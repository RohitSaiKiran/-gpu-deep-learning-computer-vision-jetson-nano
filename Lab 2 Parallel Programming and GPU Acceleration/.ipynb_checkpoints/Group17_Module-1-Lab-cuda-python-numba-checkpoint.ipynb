{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YAYBnOoiwU6X"
   },
   "source": [
    "# **Introduction to CUDA Python with Numba**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zFiFlXrTutaz"
   },
   "source": [
    "## **CONCEPT 1: What is Numba?**\n",
    "\n",
    "Numba is a **just-in-time, type-specializing, function compiler** for accelerating **numerically-focused** Python. Let's break down those terms:\n",
    "\n",
    "- **function compiler:** Numba compiles Python functions, not entire applications, and not parts of functions. Numba does not replace your Python interpreter, but is just another Python module that can turn a function into a (usually) faster function.\n",
    "- **type-specializing:** Numba speeds up your function by generating a specialized implementation for the specific data types you are using. Python functions are designed to operate on generic data types, which makes them very flexible, but also very slow. In practice, you only will call a function with a small number of argument types, so Numba will generate a fast implementation for each set of types.\n",
    "- **just-in-time:** Numba translates functions when they are first called. This ensures the compiler knows what argument types you will be using. This also allows Numba to be used interactively in a Jupyter notebook just as easily as a traditional application\n",
    "- **numerically-focused:** Currently, Numba is focused on numerical data types, like int, float, and complex. There is very limited string processing support, and many string use cases are not going to work well on the GPU. To get best results with Numba, you will likely be using NumPy arrays.\n",
    "\n",
    "The most common way to use Numba is through its collection of decorators that can be applied to your functions to instruct Numba to compile them. When a call is made to a Numba decorated function it is compiled to machine code “just-in-time” for execution and all or part of your code can subsequently run at native machine code speed!\n",
    "\n",
    "Numba supports CUDA GPU programming by directly compiling a restricted subset of Python code into CUDA kernels and device functions following the CUDA execution model. Kernels written in Numba appear to have direct access to NumPy arrays. NumPy arrays are transferred between the CPU and the GPU automatically.\n",
    "\n",
    "[Documentation](https://numba.readthedocs.io/en/stable/cuda/index.html)\n",
    "\n",
    "#### **Terminology**\n",
    "* **host**: the CPU\n",
    "* **device**: the GPU\n",
    "* **host memory**: the system main memory\n",
    "* **device memory**: onboard memory on a GPU card\n",
    "* **kernels**: a GPU function launched by the host and executed on the device\n",
    "* **device function**: a GPU function executed on the device which can only be called from the device (i.e. from a kernel or another device function)\n",
    "\n",
    "Most CUDA programming facilities exposed by Numba map directly to the CUDA C language offered by NVIDIA. Therefore, it is recommended you read the official [CUDA C programming guide](https://docs.nvidia.com/cuda/cuda-c-programming-guide/).\n",
    "\n",
    "## **CONCEPT 2: How does Numba work?**\n",
    "\n",
    "Numba reads the Python bytecode for a decorated function and combines this with information about the types of the input arguments to the function. It analyzes and optimizes your code, and finally uses the LLVM compiler library to generate a machine code version of your function, tailored to your CPU capabilities. This compiled version is then used every time your function is called.\n",
    "\n",
    "![Numba flowcart](../numba_flowcart.png)\n",
    "\n",
    "### **Other things of interest:**\n",
    "\n",
    "Numba has quite a few decorators:\n",
    "- `@jit` - compile the decorated function on-the-fly to produce efficient machine code. [Docs are here](https://numba.pydata.org/numba-doc/latest/reference/jit-compilation.html)\n",
    "- `@njit` - this is an alias for `@jit(nopython=True)` as it is so commonly used!\n",
    "- `@vectorize` - produces NumPy `ufunc` s (with all the `ufunc` methods supported). [Docs are here](https://numba.pydata.org/numba-doc/latest/user/vectorize.html#vectorize).\n",
    "- `@guvectorize` - produces NumPy generalized `ufunc` s. [Docs are here](https://numba.pydata.org/numba-doc/latest/user/vectorize.html#guvectorize).\n",
    "- `@stencil` - declare a function as a kernel for a stencil like operation. [Docs are here](https://numba.pydata.org/numba-doc/latest/user/stencil.html#numba-stencil).\n",
    "- `@jitclass` - for jit aware classes. [Docs are here](https://numba.pydata.org/numba-doc/latest/user/jitclass.html#jitclass).\n",
    "- `@cfunc` - declare a function for use as a native call back (to be called from C/C++ etc). [Docs are here](https://numba.pydata.org/numba-doc/latest/user/cfunc.html#cfunc).\n",
    "- `@overload` - register your own implementation of a function for use in nopython mode, e.g. `@overload(scipy.special.j0)`. [Docs are here](https://numba.pydata.org/numba-doc/latest/extending/high-level.html#high-level-extending).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MCcozMtIqiMJ"
   },
   "source": [
    "# **Tutorial: Numba Basics**\n",
    "\n",
    "For this tutorial, we will learn how to write a Numba function and compile it for the CPU, how to create a universal Numpy functions and how to write device functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wi9Jb2xqzaUn"
   },
   "source": [
    "## **Compiling Python code with @jit**\n",
    "\n",
    "Numba provides several utilities for code generation, but its central feature is the numba.jit() decorator with an explicit signature. Using Numba decorator @jit, which creates a normal function for execution on the CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xXCKBYsDv4Uv"
   },
   "source": [
    "### Step 1: Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "uLBqA0-Atq5_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "from decimal import Decimal\n",
    "\n",
    "import numba\n",
    "from numba import jit\n",
    "from numba import vectorize \n",
    "from numba import guvectorize\n",
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "tdnVos7OuV39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.53.1\n"
     ]
    }
   ],
   "source": [
    "# Checking Numba version\n",
    "print(numba.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EC35OoQjuklK"
   },
   "source": [
    "### Step 2: Compiling functions on the CPU\n",
    "\n",
    "We will write the first Numba function and compile it for the CPU. The Numba compiler is typically enabled by applying a decorator to a Python function. Decorators are functions that transform Python functions. Here we will use the CPU compilation decorator:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pLSwOJCsszt6"
   },
   "source": [
    " Let’s start by peeking at the numba.jit string-doc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "vKvE0BDPswcR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    This decorator is used to compile a Python function into native code.\n",
      "\n",
      "    Args\n",
      "    -----\n",
      "    signature_or_function:\n",
      "        The (optional) signature or list of signatures to be compiled.\n",
      "        If not passed, required signatures will be compiled when the\n",
      "        decorated function is called, depending on the argument values.\n",
      "        As a convenience, you can directly pass the function to be compiled\n",
      "        instead.\n",
      "\n",
      "    locals: dict\n",
      "        Mapping of local variable names to Numba types. Used to override the\n",
      "        types deduced by Numba's type inference engine.\n",
      "\n",
      "    target (deprecated): str\n",
      "        Specifies the target platform to compile for. Valid targets are cpu,\n",
      "        gpu, npyufunc, and cuda. Defaults to cpu.\n",
      "\n",
      "    pipeline_class: type numba.compiler.CompilerBase\n",
      "            The compiler pipeline type for customizing the compilation stages.\n",
      "\n",
      "    options:\n",
      "        For a cpu target, valid options are:\n",
      "            nopython: bool\n",
      "                Set to True to disable the use of PyObjects and Python API\n",
      "                calls. The default behavior is to allow the use of PyObjects\n",
      "                and Python API. Default value is False.\n",
      "\n",
      "            forceobj: bool\n",
      "                Set to True to force the use of PyObjects for every value.\n",
      "                Default value is False.\n",
      "\n",
      "            looplift: bool\n",
      "                Set to True to enable jitting loops in nopython mode while\n",
      "                leaving surrounding code in object mode. This allows functions\n",
      "                to allocate NumPy arrays and use Python objects, while the\n",
      "                tight loops in the function can still be compiled in nopython\n",
      "                mode. Any arrays that the tight loop uses should be created\n",
      "                before the loop is entered. Default value is True.\n",
      "\n",
      "            error_model: str\n",
      "                The error-model affects divide-by-zero behavior.\n",
      "                Valid values are 'python' and 'numpy'. The 'python' model\n",
      "                raises exception.  The 'numpy' model sets the result to\n",
      "                *+/-inf* or *nan*. Default value is 'python'.\n",
      "\n",
      "            inline: str or callable\n",
      "                The inline option will determine whether a function is inlined\n",
      "                at into its caller if called. String options are 'never'\n",
      "                (default) which will never inline, and 'always', which will\n",
      "                always inline. If a callable is provided it will be called with\n",
      "                the call expression node that is requesting inlining, the\n",
      "                caller's IR and callee's IR as arguments, it is expected to\n",
      "                return Truthy as to whether to inline.\n",
      "                NOTE: This inlining is performed at the Numba IR level and is in\n",
      "                no way related to LLVM inlining.\n",
      "\n",
      "            boundscheck: bool or None\n",
      "                Set to True to enable bounds checking for array indices. Out\n",
      "                of bounds accesses will raise IndexError. The default is to\n",
      "                not do bounds checking. If False, bounds checking is disabled,\n",
      "                out of bounds accesses can produce garbage results or segfaults.\n",
      "                However, enabling bounds checking will slow down typical\n",
      "                functions, so it is recommended to only use this flag for\n",
      "                debugging. You can also set the NUMBA_BOUNDSCHECK environment\n",
      "                variable to 0 or 1 to globally override this flag. The default\n",
      "                value is None, which under normal execution equates to False,\n",
      "                but if debug is set to True then bounds checking will be\n",
      "                enabled.\n",
      "\n",
      "    Returns\n",
      "    --------\n",
      "    A callable usable as a compiled function.  Actual compiling will be\n",
      "    done lazily if no explicit signatures are passed.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    The function can be used in the following ways:\n",
      "\n",
      "    1) jit(signatures, target='cpu', **targetoptions) -> jit(function)\n",
      "\n",
      "        Equivalent to:\n",
      "\n",
      "            d = dispatcher(function, targetoptions)\n",
      "            for signature in signatures:\n",
      "                d.compile(signature)\n",
      "\n",
      "        Create a dispatcher object for a python function.  Then, compile\n",
      "        the function with the given signature(s).\n",
      "\n",
      "        Example:\n",
      "\n",
      "            @jit(\"int32(int32, int32)\")\n",
      "            def foo(x, y):\n",
      "                return x + y\n",
      "\n",
      "            @jit([\"int32(int32, int32)\", \"float32(float32, float32)\"])\n",
      "            def bar(x, y):\n",
      "                return x + y\n",
      "\n",
      "    2) jit(function, target='cpu', **targetoptions) -> dispatcher\n",
      "\n",
      "        Create a dispatcher function object that specializes at call site.\n",
      "\n",
      "        Examples:\n",
      "\n",
      "            @jit\n",
      "            def foo(x, y):\n",
      "                return x + y\n",
      "\n",
      "            @jit(target='cpu', nopython=True)\n",
      "            def bar(x, y):\n",
      "                return x + y\n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(numba.jit.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eNpIFFqMtBi6"
   },
   "source": [
    "The recommended way to use the @jit decorator is to let Numba decide when and how to optimize. Let's make a compiled version of a function. In this mode, compilation will be deferred until the first function execution. Numba will infer the argument types at call time, and generate optimized code based on this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "UHWsibwZ0yHV"
   },
   "outputs": [],
   "source": [
    "nsamples = 2000\n",
    "# JIT compile a python function conforming to the CUDA-Python specification. To define a CUDA kernel:\n",
    "@jit\n",
    "def monte_carlo_pi(nsamples):\n",
    "    acc = 0\n",
    "    for i in range(nsamples):\n",
    "        x = random.random()\n",
    "        y = random.random()\n",
    "        if (x**2 + y**2) < 1.0:\n",
    "            acc += 1\n",
    "    return 4.0 * acc / nsamples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "groaqP6RCF-A"
   },
   "source": [
    "### Step 3: Benchmarking\n",
    "\n",
    "Measuring the performance of your new code is an important part. Let's see if we actuall speed up between the compiled and uncompiled versions. The easiest way to do is in the Jupyter notebook is to use **%timeit** function.\n",
    " **.py_func** attribute that can be used to access the original uncompiled Python function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "AwAZZKU80y0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.42 ms ± 10.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit monte_carlo_pi.py_func(nsamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "HFN3hD4A0zAl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 µs ± 4.82 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit monte_carlo_pi(nsamples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OYRFGJGh2nDy"
   },
   "source": [
    "The Numba-compiled version had a significant speed-up with this function!\n",
    "\n",
    "### **Signature specifications**\n",
    "\n",
    "In order to generate fast code, the compiler needs type information for the code. This allows a direct mapping from the Python operations to the appropriate machine instruction without any type check/dispatch mechanism. \n",
    "\n",
    "Explicit `@jit` signatures can use a number of types. Here are some common ones:\n",
    "\n",
    "- `void` is the return type of functions returning nothing (which actually return `None` when called from Python)\n",
    "- `intp` and `uintp` are pointer-sized integers (signed and unsigned, respectively)\n",
    "- `intc` and `uintc` are equivalent to C `int` and `unsigned int` integer types\n",
    "- `int8`, `uint8`, `int16`, `uint16`, `int32`, `uint32`, `int64`, `uint64` are fixed-width integers of the corresponding bit width (signed and unsigned)\n",
    "- `float32` and `float64` are single- and double-precision floating-point numbers, respectively\n",
    "- `complex64` and `complex128` are single- and double-precision complex numbers, respectively\n",
    "- array types can be specified by indexing any numeric type, e.g. `float32[:]` for a one-dimensional single-precision array or `int8[:,:]` for a two-dimensional array of 8-bit integers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deJvvQSrbimP"
   },
   "source": [
    "### Step 4: Compilation options\n",
    "\n",
    "The Numba @jit decorator fundamentally operates in two compilation modes:\n",
    "- `nopython mode`\n",
    "- `object mode`\n",
    "\n",
    "The behaviour of the **nopython** compilation mode is to essentially compile the decorated function so that it will run entirely without the involvement of the Python interpreter. This is the recommended and best-practice way to use the Numba jit decorator as it leads to the best performance.\n",
    "\n",
    "Should the compilation in **nopython mode** fail, Numba can compile using **object mode**. This is a fall back mode for the @jit decorator if **nopython=True** is not set. In this mode Numba will identify loops that it can compile and compile those into functions that run in machine code, and it will run the rest of the code in the interpreter. For best performance avoid using this mode!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4p7QkU1FJOp"
   },
   "source": [
    "Numba cannot compile all Python code. Some functions don't have a Numba-translation, and some kinds of Python types can't be efficiently compiled at all (yet). For example, Numba does not support dictionaries (as of this tutorial):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "p_yCRYEwFWNG"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-9ab63214e97a>:1: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"cannot_compile\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at <ipython-input-8-9ab63214e97a> (3)\n",
      "\n",
      "File \"<ipython-input-8-9ab63214e97a>\", line 3:\n",
      "def cannot_compile(x):\n",
      "    return x['key']\n",
      "    ^\n",
      "\n",
      "  @jit\n",
      "/usr/local/lib/python3.6/dist-packages/numba/core/object_mode_passes.py:152: NumbaWarning: Function \"cannot_compile\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"<ipython-input-8-9ab63214e97a>\", line 2:\n",
      "@jit\n",
      "def cannot_compile(x):\n",
      "^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/usr/local/lib/python3.6/dist-packages/numba/core/object_mode_passes.py:162: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"<ipython-input-8-9ab63214e97a>\", line 2:\n",
      "@jit\n",
      "def cannot_compile(x):\n",
      "^\n",
      "\n",
      "  state.func_ir.loc))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'value'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@jit\n",
    "def cannot_compile(x):\n",
    "    return x['key']\n",
    "\n",
    "cannot_compile(dict(key='value'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e7CTP84yFzzD"
   },
   "source": [
    "By default, Numba will fall back to a mode, called \"object mode,\" which does not do type-specialization. Object mode exists to enable other Numba functionality, but in many cases, you want Numba to tell you if type inference fails. You can force \"nopython mode\" (the other compilation mode) by passing arguments to the decorator:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pmbgM6h24Hmx"
   },
   "source": [
    "Let's see nopython mode. The nopython mode will generate the best performance, but has limitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Jg7iyMX9JzG3"
   },
   "outputs": [],
   "source": [
    "#function without error\n",
    "@jit(\"void(f4[:])\",nopython=True)\n",
    "def squared(a):\n",
    "    squared_val = a*a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8mEK-im0d4Yj"
   },
   "source": [
    "\n",
    "Types that can’t be inferred by the compiler in the nopython mode and it will generate an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "WPqVFwR-c11S"
   },
   "outputs": [
    {
     "ename": "TypingError",
     "evalue": "Failed in nopython mode pipeline (step: nopython frontend)\nUntyped global name 'Decimal': Cannot determine Numba type of <class 'type'>\n\nFile \"<ipython-input-10-f0c510dd42d9>\", line 7:\ndef squared(a):\n    <source elided>\n    squared_val = a*a\n    val = Decimal(100)\n    ^\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypingError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f0c510dd42d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#nopython mode set to True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"void(f4[:])\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnopython\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msquared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0msquared_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numba/core/decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtypeinfer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_dispatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0msig\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msigs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m                     \u001b[0mdisp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m                 \u001b[0mdisp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdisp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numba/core/dispatcher.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, sig)\u001b[0m\n\u001b[1;32m    907\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrigger_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"numba:compile\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mev_details\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                         \u001b[0mcres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mForceLiteralArg\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                         \u001b[0;32mdef\u001b[0m \u001b[0mfolded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numba/core/dispatcher.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, args, return_type)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compile_cached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numba/core/dispatcher.py\u001b[0m in \u001b[0;36m_compile_cached\u001b[0;34m(self, args, return_type)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTypingError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_failed_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numba/core/dispatcher.py\u001b[0m in \u001b[0;36m_compile_core\u001b[0;34m(self, args, return_type)\u001b[0m\n\u001b[1;32m    109\u001b[0m                                       \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                                       \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                                       pipeline_class=self.pipeline_class)\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;31m# Check typing error if object mode is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtyping_error\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_pyobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numba/core/compiler.py\u001b[0m in \u001b[0;36mcompile_extra\u001b[0;34m(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class)\u001b[0m\n\u001b[1;32m    604\u001b[0m     pipeline = pipeline_class(typingctx, targetctx, library,\n\u001b[1;32m    605\u001b[0m                               args, return_type, flags, locals)\n\u001b[0;32m--> 606\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_extra\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numba/core/compiler.py\u001b[0m in \u001b[0;36mcompile_extra\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlifted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlifted_from\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile_bytecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompile_ir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_ir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlifted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlifted_from\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numba/core/compiler.py\u001b[0m in \u001b[0;36m_compile_bytecode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \"\"\"\n\u001b[1;32m    414\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc_ir\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compile_ir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numba/core/compiler.py\u001b[0m in \u001b[0;36m_compile_core\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    393\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfail_reason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mis_final_pipeline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCompilerError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"All available pipelines exhausted\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numba/core/compiler.py\u001b[0m in \u001b[0;36m_compile_core\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m                 \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numba/core/compiler_machinery.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    337\u001b[0m                     \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpass_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m                 \u001b[0mpatched_exception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_patch_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mpatched_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdependency_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numba/core/compiler_machinery.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    328\u001b[0m                 \u001b[0mpass_inst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pass_registry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpass_inst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpass_inst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompilerPass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_runPass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpass_inst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Legacy pass in use\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numba/core/compiler_lock.py\u001b[0m in \u001b[0;36m_acquire_compile_lock\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_acquire_compile_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_acquire_compile_lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numba/core/compiler_machinery.py\u001b[0m in \u001b[0;36m_runPass\u001b[0;34m(self, index, pss, internal_state)\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mmutated\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_initialization\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSimpleTimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpass_time\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m             \u001b[0mmutated\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSimpleTimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfinalize_time\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0mmutated\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_finalizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numba/core/compiler_machinery.py\u001b[0m in \u001b[0;36mcheck\u001b[0;34m(func, compiler_state)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompiler_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             \u001b[0mmangled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompiler_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmangled\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                 msg = (\"CompilerPass implementations should return True/False. \"\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numba/core/typed_passes.py\u001b[0m in \u001b[0;36mrun_pass\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                 raise_errors=self._raise_errors)\n\u001b[0m\u001b[1;32m    111\u001b[0m             \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypemap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtypemap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;31m# save errors in case of partial typing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numba/core/typed_passes.py\u001b[0m in \u001b[0;36mtype_inference_stage\u001b[0;34m(typingctx, interp, args, return_type, locals, raise_errors)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0minfer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0minfer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_constraint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;31m# return errors in case of partial typing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0merrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraise_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_errors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numba/core/typeinfer.py\u001b[0m in \u001b[0;36mbuild_constraint\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0minst\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstrain_statement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreturn_types_from_partial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numba/core/typeinfer.py\u001b[0m in \u001b[0;36mconstrain_statement\u001b[0;34m(self, inst)\u001b[0m\n\u001b[1;32m   1369\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconstrain_statement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAssign\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypeof_assign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1372\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSetItem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypeof_setitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numba/core/typeinfer.py\u001b[0m in \u001b[0;36mtypeof_assign\u001b[0;34m(self, inst)\u001b[0m\n\u001b[1;32m   1440\u001b[0m                                               src=value.name, loc=inst.loc))\n\u001b[1;32m   1441\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGlobal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFreeVar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypeof_global\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypeof_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numba/core/typeinfer.py\u001b[0m in \u001b[0;36mtypeof_global\u001b[0;34m(self, inst, target, gvar)\u001b[0m\n\u001b[1;32m   1540\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtypeof_global\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1542\u001b[0;31m             \u001b[0mtyp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve_value_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypingError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1544\u001b[0m             if (gvar.name == self.func_id.func_name\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numba/core/typeinfer.py\u001b[0m in \u001b[0;36mresolve_value_type\u001b[0;34m(self, inst, val)\u001b[0m\n\u001b[1;32m   1461\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1462\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1463\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtypeof_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypingError\u001b[0m: Failed in nopython mode pipeline (step: nopython frontend)\nUntyped global name 'Decimal': Cannot determine Numba type of <class 'type'>\n\nFile \"<ipython-input-10-f0c510dd42d9>\", line 7:\ndef squared(a):\n    <source elided>\n    squared_val = a*a\n    val = Decimal(100)\n    ^\n"
     ]
    }
   ],
   "source": [
    "#function that contains a variable whose type can’t be inferred by the compiler\n",
    "#nopython mode set to True\n",
    "\n",
    "@jit(\"void(f4[:])\",nopython=True)\n",
    "def squared(a):\n",
    "    squared_val = a*a\n",
    "    val = Decimal(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5gVxFuSQtj6B"
   },
   "source": [
    "If we don’t specify anything like in the function below, where nopython mode is not set to True, the compilation is falling back to object mode and produces a warning but not an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "awW0Ijzqd3gM"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-b2ef140a0f64>:5: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"squared\" failed type inference due to: Untyped global name 'Decimal': Cannot determine Numba type of <class 'type'>\n",
      "\n",
      "File \"<ipython-input-11-b2ef140a0f64>\", line 8:\n",
      "def squared(a):\n",
      "    <source elided>\n",
      "    squared_val = a*a\n",
      "    val = Decimal(100)\n",
      "    ^\n",
      "\n",
      "  @jit(\"void(f4[:])\")\n",
      "/usr/local/lib/python3.6/dist-packages/numba/core/object_mode_passes.py:152: NumbaWarning: Function \"squared\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"<ipython-input-11-b2ef140a0f64>\", line 6:\n",
      "@jit(\"void(f4[:])\")\n",
      "def squared(a):\n",
      "^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/usr/local/lib/python3.6/dist-packages/numba/core/object_mode_passes.py:162: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"<ipython-input-11-b2ef140a0f64>\", line 6:\n",
      "@jit(\"void(f4[:])\")\n",
      "def squared(a):\n",
      "^\n",
      "\n",
      "  state.func_ir.loc))\n"
     ]
    }
   ],
   "source": [
    "# function that contains a variable whose type can’t be inferred by the compiler\n",
    "# nopython mode not set to True\n",
    "# compilation is falling back to object mode\n",
    "\n",
    "@jit(\"void(f4[:])\")\n",
    "def squared(a):\n",
    "    squared_val = a*a\n",
    "    val = Decimal(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vxtpI00D3_XH"
   },
   "source": [
    "### Step 4: Type inference\n",
    "\n",
    "The objective of type inference is assigning a type to every single value in the function. The type of a value can either be:\n",
    "\n",
    "* Implicit, in the case of providing an object that will provide its type. For e.g. in literals.\n",
    "* Explicit, in the case of the programmer explicitly writing the type of a given value. For e.g. when a signature is given to numba.jit. That signature explicitly types the arguments.\n",
    "* Inferred, when the type is deduced from an operation and the types of its operands. For e.g. inferring that the type of a + b, when a and b are of type int is going to be an int\n",
    "Type inference is the process by which all the types that are neither implicit nor explicit are deduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Ph3zzdBp3r7A"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monte_carlo_pi (int64,)\n",
      "--------------------------------------------------------------------------------\n",
      "# File: <ipython-input-5-70a9c87dfcd7>\n",
      "# --- LINE 3 --- \n",
      "\n",
      "@jit\n",
      "\n",
      "# --- LINE 4 --- \n",
      "\n",
      "def monte_carlo_pi(nsamples):\n",
      "\n",
      "    # --- LINE 5 --- \n",
      "    # label 0\n",
      "    #   nsamples = arg(0, name=nsamples)  :: int64\n",
      "    #   acc = const(int, 0)  :: Literal[int](0)\n",
      "\n",
      "    acc = 0\n",
      "\n",
      "    # --- LINE 6 --- \n",
      "    #   jump 6\n",
      "    # label 6\n",
      "    #   jump 8\n",
      "    # label 8\n",
      "    #   $8.1 = global(range: <class 'range'>)  :: Function(<class 'range'>)\n",
      "    #   $8.3 = call $8.1(nsamples, func=$8.1, args=[Var(nsamples, <ipython-input-5-70a9c87dfcd7>:5)], kws=(), vararg=None)  :: (int64,) -> range_state_int64\n",
      "    #   del $8.1\n",
      "    #   $8.4 = getiter(value=$8.3)  :: range_iter_int64\n",
      "    #   del $8.3\n",
      "    #   $phi16.1 = $8.4  :: range_iter_int64\n",
      "    #   del $8.4\n",
      "    #   jump 16\n",
      "    # label 16\n",
      "    #   $16.2 = iternext(value=$phi16.1)  :: pair<int64, bool>\n",
      "    #   $16.3 = pair_first(value=$16.2)  :: int64\n",
      "    #   $16.4 = pair_second(value=$16.2)  :: bool\n",
      "    #   del $16.2\n",
      "    #   $phi18.1 = $16.3  :: int64\n",
      "    #   $phi66.1 = $16.3  :: int64\n",
      "    #   del $phi66.1\n",
      "    #   del $16.3\n",
      "    #   $phi66.2 = $phi16.1  :: range_iter_int64\n",
      "    #   del $phi66.2\n",
      "    #   branch $16.4, 18, 66\n",
      "    # label 18\n",
      "    #   del $16.4\n",
      "    #   i = $phi18.1  :: int64\n",
      "    #   del i\n",
      "    #   del $phi18.1\n",
      "    # label 69\n",
      "    #   jump 16\n",
      "\n",
      "    for i in range(nsamples):\n",
      "\n",
      "        # --- LINE 7 --- \n",
      "        #   $18.2 = global(random: <module 'random' from '/usr/lib/python3.6/random.py'>)  :: Module(<module 'random' from '/usr/lib/python3.6/random.py'>)\n",
      "        #   $18.3 = getattr(value=$18.2, attr=random)  :: Function(random.random)\n",
      "        #   del $18.2\n",
      "        #   x = call $18.3(func=$18.3, args=[], kws=(), vararg=None)  :: () -> float64\n",
      "        #   del $18.3\n",
      "\n",
      "        x = random.random()\n",
      "\n",
      "        # --- LINE 8 --- \n",
      "        #   $18.5 = global(random: <module 'random' from '/usr/lib/python3.6/random.py'>)  :: Module(<module 'random' from '/usr/lib/python3.6/random.py'>)\n",
      "        #   $18.6 = getattr(value=$18.5, attr=random)  :: Function(random.random)\n",
      "        #   del $18.5\n",
      "        #   y = call $18.6(func=$18.6, args=[], kws=(), vararg=None)  :: () -> float64\n",
      "        #   del $18.6\n",
      "\n",
      "        y = random.random()\n",
      "\n",
      "        # --- LINE 9 --- \n",
      "        #   $const18.9 = const(int, 2)  :: Literal[int](2)\n",
      "        #   $18.10 = x ** $const18.9  :: float64\n",
      "        #   del x\n",
      "        #   del $const18.9\n",
      "        #   $const18.12 = const(int, 2)  :: Literal[int](2)\n",
      "        #   $18.13 = y ** $const18.12  :: float64\n",
      "        #   del y\n",
      "        #   del $const18.12\n",
      "        #   $18.14 = $18.10 + $18.13  :: float64\n",
      "        #   del $18.13\n",
      "        #   del $18.10\n",
      "        #   $const18.15 = const(float, 1.0)  :: float64\n",
      "        #   $18.16 = $18.14 < $const18.15  :: bool\n",
      "        #   del $const18.15\n",
      "        #   del $18.14\n",
      "        #   bool54 = global(bool: <class 'bool'>)  :: Function(<class 'bool'>)\n",
      "        #   $54pred = call bool54($18.16, func=bool54, args=(Var($18.16, <ipython-input-5-70a9c87dfcd7>:9),), kws=(), vararg=None)  :: (bool,) -> bool\n",
      "        #   del bool54\n",
      "        #   del $18.16\n",
      "        #   branch $54pred, 56, 69\n",
      "\n",
      "        if (x**2 + y**2) < 1.0:\n",
      "\n",
      "            # --- LINE 10 --- \n",
      "            #   acc.2 = phi(incoming_values=[Var(acc, <ipython-input-5-70a9c87dfcd7>:5), Var(acc.3, <ipython-input-5-70a9c87dfcd7>:10)], incoming_blocks=[8, 69])  :: int64\n",
      "            #   del acc.3\n",
      "            # label 56\n",
      "            #   del $54pred\n",
      "            #   $const56.2 = const(int, 1)  :: Literal[int](1)\n",
      "            #   $56.3 = inplace_binop(fn=<built-in function iadd>, immutable_fn=<built-in function add>, lhs=acc.2, rhs=$const56.2, static_lhs=Undefined, static_rhs=Undefined)  :: int64\n",
      "            #   del $const56.2\n",
      "            #   acc.1 = $56.3  :: int64\n",
      "            #   del $56.3\n",
      "            #   jump 69\n",
      "            # label 66\n",
      "            #   del $54pred\n",
      "            #   acc.3 = phi(incoming_values=[Var(acc.1, <ipython-input-5-70a9c87dfcd7>:10), Var(acc.2, <ipython-input-5-70a9c87dfcd7>:10)], incoming_blocks=[56, 18])  :: int64\n",
      "            #   del acc.2\n",
      "\n",
      "            acc += 1\n",
      "\n",
      "    # --- LINE 11 --- \n",
      "    #   del acc.1\n",
      "    #   del acc\n",
      "    #   del $phi18.1\n",
      "    #   del $phi16.1\n",
      "    #   del $16.4\n",
      "    #   jump 68\n",
      "    # label 68\n",
      "    #   $const68.1 = const(float, 4.0)  :: float64\n",
      "    #   $68.3 = $const68.1 * acc.2  :: float64\n",
      "    #   del acc.2\n",
      "    #   del $const68.1\n",
      "    #   $68.5 = $68.3 / nsamples  :: float64\n",
      "    #   del nsamples\n",
      "    #   del $68.3\n",
      "    #   $68.6 = cast(value=$68.5)  :: float64\n",
      "    #   del $68.5\n",
      "    #   return $68.6\n",
      "\n",
      "    return 4.0 * acc / nsamples\n",
      "\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Let’s illustrate how type inference works with numba.jit. \n",
    "# We can see the result of type inference by using the .inspect_types() method, which prints an annotated version of the source code.\n",
    "\n",
    "monte_carlo_pi.inspect_types()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xj99cpmOEz6P"
   },
   "source": [
    "Note that Numba's type names tend to mirror the NumPy type names, so a Python float is a float64 (also called \"double precision\" in other languages). Taking a look at the data types can sometimes be important in GPU code because the performance of float32 and float64 computations will be very different on CUDA devices. An accidental upcast can dramatically slow down a function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q1LiE4Wozj5z"
   },
   "source": [
    "## **Creating Numpy universal functions**\n",
    "\n",
    "#### **CUDA Basics**\n",
    "\n",
    "There are two basic approaches to GPU programming in Numba:\n",
    "\n",
    "- ufuncs/gufuncs\n",
    "- CUDA Python kernels. [See documentation here](https://numba.pydata.org/numba-doc/latest/cuda/kernels.html)\n",
    "\n",
    "We will not go into the CUDA hardware too much in this section, but the most important thing to remember is that the hardware is designed for data parallelism. Maximum throughput is achieved when you are computing the same operations on many different elements at once.\n",
    "\n",
    "Universal functions are naturally data parallel, so we will begin with them.\n",
    "\n",
    "#### **Universal Functions** \n",
    "\n",
    "Numba supports generating two types of universal functions:\n",
    "\n",
    "- Those which operate on scalars, these are “universal functions” or ufuncs (@vectorize below).\n",
    "- Those which operate on higher dimensional arrays and scalars, these are “generalized universal functions” or gufuncs (@guvectorize below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kM95lYiZ0fs7"
   },
   "source": [
    "#### **Universal functions**\n",
    "\n",
    "Universal functions(ufuncs) are functions that broadcast an elementwise operation across input arrays of varying numbers of dimensions. Most NumPy functions are ufuncs, and Numba makes it easy to compile custom ufuncs using the @vectorize decorator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zGoh-ohYQ2Fv"
   },
   "source": [
    "#### Step 1: \n",
    "\n",
    "The NumPy documentation has a much more extensive discussion of ufuncs:\n",
    "\n",
    "https://docs.scipy.org/doc/numpy/reference/ufuncs.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "wYM7ljjUubTa"
   },
   "outputs": [],
   "source": [
    "# Applying sqrt() method in Numpy\n",
    "def cpu_sqrt(x):\n",
    "  return math.sqrt(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "shfhyJwVwv8n"
   },
   "outputs": [],
   "source": [
    "# Making ufuncs for the CPU\n",
    "@vectorize\n",
    "def cpu_numba_sqrt(x):\n",
    "  return math.sqrt(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "LQLzjk2XxS_8"
   },
   "outputs": [],
   "source": [
    "# Making a ufunc for the GPU\n",
    "# Generating a ufunc that uses CUDA requires giving an explicit type signature and setting the target attribute\n",
    "@vectorize(['float32(float32)'], target='cuda')\n",
    "def gpu_numba_sqrt(x):\n",
    "    return math.sqrt(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "p9v2Oq17xb_B"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.71 µs ± 30.5 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.sqrt(25) # NumPy on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "s7RMJZQmxk7B"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622 ns ± 3.58 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit cpu_sqrt(25)  # NumPy on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Pr0DbIVJxtWB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.36 µs ± 28.2 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit cpu_numba_sqrt(25) # Numba on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "dpB23pA_x2N6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.74 ms ± 398 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit gpu_numba_sqrt(25) # Numba on GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wzRChAmjylCU"
   },
   "source": [
    "Why did we see an increase in the processing time?\n",
    "\n",
    "An overhead is introduced by Numba to each function call that is larger than the function call overhead of Python itself. \n",
    "\n",
    "Functions that are quick to compute are affected by this.\n",
    "\n",
    "Since the function here is too simple to run on the GPU, we experience longer processing time due to data transfer operations taking place.\n",
    "\n",
    "* input data is transferred to the GPU memory\n",
    "* the square root is calculated on the GPU\n",
    "* the resulting value is sent back to the host system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cKr6k1Lrf7GH"
   },
   "source": [
    "#### **Generalized ufuncs on the GPU**\n",
    "\n",
    "In generalized ufuncs (gufuncs), the calculation can deal with a sub-array of the input array, and return an array of different dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "hVAb9_6e5VTG"
   },
   "outputs": [],
   "source": [
    "#calculating the sum of elements in each row of the array\n",
    "@guvectorize(['(float32[:], float32[:])'],\n",
    "             '(n)->()',                \n",
    "             target='cuda')\n",
    "def calc_sum(a, out):\n",
    "    sum = 0\n",
    "    for val in a: \n",
    "        sum += val\n",
    "    out[0] = sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "8hUPmGrFggZz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  2.,  3.,  4.],\n",
       "       [ 5.,  6.,  7.,  8.,  9.],\n",
       "       [10., 11., 12., 13., 14.],\n",
       "       [15., 16., 17., 18., 19.],\n",
       "       [20., 21., 22., 23., 24.],\n",
       "       [25., 26., 27., 28., 29.],\n",
       "       [30., 31., 32., 33., 34.],\n",
       "       [35., 36., 37., 38., 39.],\n",
       "       [40., 41., 42., 43., 44.],\n",
       "       [45., 46., 47., 48., 49.]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(50).reshape(10, 5).astype(np.float32)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "V6aGey3jgkWK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 10.,  35.,  60.,  85., 110., 135., 160., 185., 210., 235.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_sum(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oZrZKvSAiSAS"
   },
   "source": [
    "## **CUDA Device Functions**\n",
    "\n",
    "Uptil now we were compiling all our code in single functions and ufuncs are great, but you should not have to cram all of your logic into a single function body. You can also create normal functions that are only called from other functions running on the GPU. These are called **device** functions.(These are similar to CUDA C functions defined with __device__.)\n",
    "\n",
    "Device functions are created with the numba.cuda.jit decorator:\n",
    "\n",
    "`add_values:` device function to sum up the elements of the array using the numba.cuda.jit decorator\n",
    "\n",
    "`calc_sum:` gufunc to make use of the add_values device function\n",
    "\n",
    "`calc_avg:` gufunc to calculate the average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "_3FwinUKiY90"
   },
   "outputs": [],
   "source": [
    "# define a device function\n",
    "@cuda.jit(device=True)\n",
    "def add_values(a): \n",
    "  sum = 0\n",
    "  for val in a: \n",
    "    sum += val\n",
    "  return sum\n",
    "\n",
    "# define a gufunc that calls our device function\n",
    "@guvectorize(['(float32[:], float32[:])'],\n",
    "             '(n)->()',                \n",
    "             target='cuda')\n",
    "def calc_sum(a, out):\n",
    "    out[0] = add_values(a)\n",
    "\n",
    "@guvectorize(['(float32[:], float32[:])'],\n",
    "             '(n)->()',                \n",
    "             target='cuda')\n",
    "def calc_avg(a, out):\n",
    "    out[0] = add_values(a)/len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "zKRmxgs3jgQk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 10.,  35.,  60.,  85., 110., 135., 160., 185., 210., 235.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "rO7lxyh6j19a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  7., 12., 17., 22., 27., 32., 37., 42., 47.], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_avg(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eyV6eVAhwLeh"
   },
   "source": [
    "# **Exercise: Numba Basics**\n",
    "\n",
    "The function below is a naive sum function that sums all the elements of a given array. Let’s get a numba version of this code running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "2giKI1AXwM2E"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500654.76649949304\n"
     ]
    }
   ],
   "source": [
    "#Write your own code\n",
    "from numba import jit\n",
    "import numpy as np\n",
    "\n",
    "def summation_array(arr):\n",
    "    total = 0.0\n",
    "    for i in range(len(arr)):\n",
    "        total += arr[i]\n",
    "    return total\n",
    "\n",
    "# Compile using jit as a function call\n",
    "summation_jit = jit()(summation_array)\n",
    "\n",
    "arr = np.random.rand(1_000_000)\n",
    "print(summation_jit(arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2MgExL7KApOC"
   },
   "source": [
    "##### **As a function call**\n",
    "\n",
    "Compile **summation_array()** function using numba.jit without providing a type-signature for the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Nt5ttiu9-P-b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499830.4227266844\n"
     ]
    }
   ],
   "source": [
    "# Write your own code\n",
    "@jit(nopython=True)\n",
    "def summation_array(arr):\n",
    "    total = 0.0\n",
    "    for i in range(len(arr)):\n",
    "        total += arr[i]\n",
    "    return total\n",
    "\n",
    "arr = np.random.rand(1_000_000)\n",
    "print(summation_array(arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ub1SSn-OAvOb"
   },
   "source": [
    "##### **As a decorater**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "GTBjAcPDA0Gg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.06 ms ± 868 ns per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "956 ms ± 5.75 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "3.62 ms ± 13.3 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# Write your own code\n",
    "arr = np.random.rand(1_000_000)\n",
    "\n",
    "# NumPy sum\n",
    "%timeit np.sum(arr)\n",
    "\n",
    "# Python loop\n",
    "def python_sum(arr):\n",
    "    total = 0.0\n",
    "    for i in range(len(arr)):\n",
    "        total += arr[i]\n",
    "    return total\n",
    "\n",
    "%timeit python_sum(arr)\n",
    "\n",
    "# Numba JIT version\n",
    "@jit(nopython=True)\n",
    "def numba_sum(arr):\n",
    "    total = 0.0\n",
    "    for i in range(len(arr)):\n",
    "        total += arr[i]\n",
    "    return total\n",
    "\n",
    "%timeit numba_sum(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K15Vv3vpGQpl"
   },
   "source": [
    "##### **Benchmarking**\n",
    "\n",
    "Compare NumPy and Numba using %timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "cNdulQtFFnvG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1 ms ± 3.27 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "3.6 ms ± 848 ns per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "# Write your own code\n",
    "import numpy as np\n",
    "\n",
    "arr = np.random.rand(1000000)\n",
    "\n",
    "# NumPy sum\n",
    "%timeit np.sum(arr)\n",
    "\n",
    "# Python loop\n",
    "%timeit summation_array(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e0IKtbZyGCjS"
   },
   "source": [
    "##### **Question: When does Numba compile codes?**\n",
    "\n",
    "Numba compiles code at runtime when the function is called for the first time with a specific set of input types. This is known as just-in-time (JIT) compilation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibjc40sgHM55"
   },
   "source": [
    "# **Tutorial: Memory Management**\n",
    "\n",
    "In order to reduce the impact of host-to-device/device-to-host bandwidth, it is best to copy data to the GPU explicitly and leave it there to amortize the cost over multiple function calls. In addition, allocating device memory can be relatively slow, so allocating GPU arrays once and refilling them with data from the host can also be a performance improvement.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "7OgmyrLDH_re"
   },
   "outputs": [],
   "source": [
    "@vectorize(['float32(float32, float32)'], target='cuda')\n",
    "def add_ufunc(x, y):\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "0buPrxtGOEWN"
   },
   "outputs": [],
   "source": [
    "n = 100000\n",
    "x = np.arange(n).astype(np.float32)\n",
    "y = 2 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "r_zmaFwmOM-J"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.77 ms ± 638 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit add_ufunc(x, y)  # Baseline performance with host arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XCAJuScsPlGq"
   },
   "source": [
    "The numba.cuda module includes a function that will copy host data to the GPU and return a CUDA device array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "-j4m47L6OXOp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<numba.cuda.cudadrv.devicearray.DeviceNDArray object at 0x7f7a983e80>\n",
      "(100000,)\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "from numba import cuda\n",
    "\n",
    "x_device = cuda.to_device(x)\n",
    "y_device = cuda.to_device(y)\n",
    "\n",
    "print(x_device)\n",
    "print(x_device.shape)\n",
    "print(x_device.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GPi-Rgo4PjLH"
   },
   "source": [
    "Device arrays can be passed to CUDA functions just like NumPy arrays, but without the copy overhead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "16Tq2D-KPqY-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.72 ms ± 9.19 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%timeit add_ufunc(x_device, y_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9p5i5RIOPtHU"
   },
   "source": [
    "That's a big performance improvement already, but we are still allocating a device array for the output of the ufunc and copying it back to the host. We can create the output buffer with the numba.cuda.device_array() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "mcEzUf8hPybJ"
   },
   "outputs": [],
   "source": [
    "out_device = cuda.device_array(shape=(n,), dtype=np.float32)  # does not initialize the contents, like np.empty()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "czWHlgXEP1yy"
   },
   "source": [
    "And then we can use a special out keyword argument to the ufunc to specify the output buffer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "i9jLNN_SP4zH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.71 ms ± 4.18 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit add_ufunc(x_device, y_device, out=out_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i4P8o8kFP7b0"
   },
   "source": [
    "Now that we have removed the device allocation and copy steps, the computation runs much faster than before. When we want to bring the device array back to the host memory, we can use the copy_to_host() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "LF7dBwiLP-do"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  3.  6.  9. 12. 15. 18. 21. 24. 27.]\n"
     ]
    }
   ],
   "source": [
    "out_host = out_device.copy_to_host()\n",
    "print(out_host[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dWtzrmPeTsSN"
   },
   "source": [
    "# **Tutorial: Writing CUDA kernels**\n",
    "\n",
    "Ufuncs and generalized ufuncs are the easiest way in Numba to use the GPU, and present an abstraction that requires minimal understanding of the CUDA programming model. However, you can not write all functions as ufuncs so you write a CUDA kernel.\n",
    "\n",
    "It's highly recommend to read Chapters 1 and 2 of the CUDA C Programming Guide to understand how to write CUDA kernels with Numba.\n",
    "- Introduction: http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#introduction\n",
    "- Programming Model: http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#programming-model\n",
    "\n",
    "![[cuda flowchart](https://camo.githubusercontent.com/87204582bdb0422a08cef47cd0bafcfd860cd522/687474703a2f2f646f63732e6e76696469612e636f6d2f637564612f637564612d632d70726f6772616d6d696e672d67756964652f67726170686963732f677269642d6f662d7468726561642d626c6f636b732e706e67)](https://camo.githubusercontent.com/87204582bdb0422a08cef47cd0bafcfd860cd522/687474703a2f2f646f63732e6e76696469612e636f6d2f637564612f637564612d632d70726f6772616d6d696e672d67756964652f67726170686963732f677269642d6f662d7468726561642d626c6f636b732e706e67)\n",
    "\n",
    "We will write a *kernel* that decribes the execution of a single thread in this hierarchy. The CUDA compiler and driver will execute the kernel across a *thread grid* that is divided into *blocks* of threads. Threads within the same block can exchange data very easily during the execution of a kernel, whereas threads in different blocks should generally not communicate with each other (with a few exceptions).\n",
    "\n",
    "Deciding the best size for the CUDA thread grid is a complex problem (and depends on both the algorithm and the specific GPU compute capability), but here are some very rough heuristics that we follow:\n",
    "\n",
    "- the size of a block should be a multiple of 32 threads, with typical block sizes between 128 and 512 threads per block.\n",
    "- the size of the grid should ensure the full GPU is utilized where possible. Launching a grid where the number of blocks is 2x-4x the number of \"multiprocessors\" on the GPU is a good starting place. Something in the range of 20 - 100 blocks is usually a good starting point.\n",
    "- The CUDA kernel launch overhead does depend on the number of blocks, so we find it best not to launch a grid where the number of threads equals the number of input elements when the input size is very big. We'll show a pattern for dealing with large inputs below.\n",
    "\n",
    "Each thread distinguishes itself from the other threads using its unique thread (`threadIdx`) and block (`blockIdx`) index values, which can be multidimensional if launched that way.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K9Li9JQBWfjH"
   },
   "source": [
    "### Step 1: Getting Started\n",
    "\n",
    "In this section, you will learn how to write your own custom CUDA kernels to do accelerated, parallel computing on a GPU, in python with the help of numba and CUDA.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "fD4_efM0WjMy"
   },
   "outputs": [],
   "source": [
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bx2b-tCFXGC6"
   },
   "source": [
    "### Step 2: Write a CUDA kernel\n",
    "\n",
    "CUDA kernels are compiled using the numba.cuda.jit decorator (not to be confused with the numba.jit decorator for the CPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "AmeAQBNgZgZK"
   },
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def add_kernel(x, y, out):\n",
    "    tx = cuda.threadIdx.x # this is the unique thread ID within a 1D block\n",
    "    ty = cuda.blockIdx.x  # Similarly, this is the unique block ID within the 1D grid\n",
    "\n",
    "    block_size = cuda.blockDim.x  # number of threads per block\n",
    "    grid_size = cuda.gridDim.x    # number of blocks in the grid\n",
    "    \n",
    "    start = tx + ty * block_size\n",
    "    stride = block_size * grid_size\n",
    "\n",
    "    # assuming x and y inputs are same length\n",
    "    for i in range(start, x.shape[0], stride):\n",
    "        out[i] = x[i] + y[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SYqEV0l6XPdd"
   },
   "source": [
    "### Step 3: Call the function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "ocISDc5TbLky"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  3.  6.  9. 12. 15. 18. 21. 24. 27.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "n = 100000\n",
    "x = np.arange(n).astype(np.float32)\n",
    "y = 2 * x\n",
    "out = np.empty_like(x)\n",
    "\n",
    "threads_per_block = 128\n",
    "blocks_per_grid = 30\n",
    "\n",
    "add_kernel[blocks_per_grid, threads_per_block](x, y, out)\n",
    "print(out[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s2mGj4LGb31E"
   },
   "source": [
    "### Step 4: Copy host data to the GPU and return a CUDA device array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "G6TNYs-ibNjD"
   },
   "outputs": [],
   "source": [
    "x_device = cuda.to_device(x)\n",
    "y_device = cuda.to_device(y)\n",
    "out_device = cuda.device_array_like(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "wbTL7Sh1cB53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.8 ms ± 18.9 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit add_kernel[blocks_per_grid, threads_per_block](x, y, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "OZIoMpgfcEsQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.81 ms ± 32.9 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit add_kernel[blocks_per_grid, threads_per_block](x_device, y_device, out_device); out_device.copy_to_host()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6X9TZkQVcR_o"
   },
   "source": [
    "## Kernel Synchronization\n",
    "\n",
    "CUDA kernel execution is designed to be asynchronous with respect to the host program. This means that the kernel launch (add_kernel[blocks_per_grid, threads_per_block](x_device, y_device, out_device)) returns immediately, allowing the CPU to continue executing while the GPU works in the background. Only host<->device memory copies or an explicit synchronization call will force the CPU to wait until previously queued CUDA kernels are complete.\n",
    "\n",
    "Always be sure to synchronize with the GPU when benchmarking CUDA kernels!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "onrOp73Fc2ZH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12 ms, sys: 0 ns, total: 12 ms\n",
      "Wall time: 14.4 ms\n"
     ]
    }
   ],
   "source": [
    "# CPU input/output arrays, implied synchronization for memory copies\n",
    "%time add_kernel[blocks_per_grid, threads_per_block](x, y, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "Ma-OyamjcIne"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 1.15 ms\n"
     ]
    }
   ],
   "source": [
    "# GPU input/output arrays, no synchronization (but force sync before and after)\n",
    "cuda.synchronize()\n",
    "%time add_kernel[blocks_per_grid, threads_per_block](x_device, y_device, out_device)\n",
    "cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "rnQzc5VAc526"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 1.56 ms\n"
     ]
    }
   ],
   "source": [
    "# GPU input/output arrays, include explicit synchronization in timing\n",
    "cuda.synchronize()\n",
    "%time add_kernel[blocks_per_grid, threads_per_block](x_device, y_device, out_device); cuda.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "buA7D_4PdLeh"
   },
   "source": [
    "# **Exercise: Writing CUDA kernels**\n",
    "\n",
    "Below statement is a pure Python implementation of a function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "mGYAgIXM3qjT"
   },
   "outputs": [],
   "source": [
    "# Python implementation\n",
    "def mandelbrot(x, y, max_iters):\n",
    "  i = 0\n",
    "  c = complex(x,y)\n",
    "  z = 0.0j\n",
    "  for i in range(max_iters):\n",
    "    z = z * z + c\n",
    "    if z.real * z.real + z.imag * z.imag >= 4:\n",
    "        return i\n",
    "  return 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6GcXfdhfGYiH"
   },
   "source": [
    "Step 1: Modify the example by compiling:\n",
    "- @jit decorator, to run as native code on the CPU\n",
    "- @cuda.jit decorator, to run on the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "vSBKZOcFc9vz"
   },
   "outputs": [],
   "source": [
    "# Write your own code here\n",
    "from numba import jit, cuda\n",
    "\n",
    "# CPU-compiled version using @jit\n",
    "@jit(nopython=True)\n",
    "def mandelbrot_cpu(x, y, max_iters):\n",
    "    c = complex(x, y)\n",
    "    z = 0.0j\n",
    "    for i in range(max_iters):\n",
    "        z = z * z + c\n",
    "        if z.real * z.real + z.imag * z.imag >= 4:\n",
    "            return i\n",
    "    return 255\n",
    "\n",
    "# GPU-compiled version using @cuda.jit\n",
    "@cuda.jit\n",
    "def mandelbrot_gpu(x_vals, y_vals, output, max_iters):\n",
    "    i, j = cuda.grid(2)\n",
    "    if i < output.shape[0] and j < output.shape[1]:\n",
    "        x = x_vals[i]\n",
    "        y = y_vals[j]\n",
    "        c = complex(x, y)\n",
    "        z = 0.0j\n",
    "        count = 0\n",
    "        for n in range(max_iters):\n",
    "            z = z * z + c\n",
    "            if z.real * z.real + z.imag * z.imag >= 4:\n",
    "                break\n",
    "            count += 1\n",
    "        output[i, j] = count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V6rmQjEeGik_"
   },
   "source": [
    "Step 2: Copy host data to the GPU and return a CUDA device array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "u4YK8Mw5GRae"
   },
   "outputs": [],
   "source": [
    "# Write your own code here\n",
    "import numpy as np\n",
    "\n",
    "# Create host data\n",
    "N = 1024\n",
    "x_vals = np.linspace(-2.0, 1.0, N).astype(np.float32)\n",
    "y_vals = np.linspace(-1.5, 1.5, N).astype(np.float32)\n",
    "output = np.zeros((N, N), dtype=np.uint8)\n",
    "\n",
    "# Transfer to device\n",
    "d_x_vals = cuda.to_device(x_vals)\n",
    "d_y_vals = cuda.to_device(y_vals)\n",
    "d_output = cuda.device_array_like(output)\n",
    "\n",
    "# Configure thread/block layout\n",
    "threadsperblock = (16, 16)\n",
    "blockspergrid_x = int(np.ceil(N / threadsperblock[0]))\n",
    "blockspergrid_y = int(np.ceil(N / threadsperblock[1]))\n",
    "blockspergrid = (blockspergrid_x, blockspergrid_y)\n",
    "\n",
    "# Run kernel\n",
    "mandelbrot_gpu[blockspergrid, threadsperblock](d_x_vals, d_y_vals, d_output, 255)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RGFmzh8oGH1j"
   },
   "source": [
    "Step 3: Can you also rewrite the mandel function using @vectorize for the CUDA target?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "i96232k2GwF3"
   },
   "outputs": [],
   "source": [
    "# Write your own code here\n",
    "from numba import vectorize\n",
    "\n",
    "@vectorize(['uint8(float32, float32)'], target='cuda')\n",
    "def mandelbrot_vectorized(x, y):\n",
    "    c = complex(x, y)\n",
    "    z = 0.0j\n",
    "    for i in range(255):\n",
    "        z = z * z + c\n",
    "        if z.real * z.real + z.imag * z.imag >= 4:\n",
    "            return i\n",
    "    return 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "YAYBnOoiwU6X",
    "zFiFlXrTutaz",
    "MCcozMtIqiMJ",
    "wi9Jb2xqzaUn",
    "xXCKBYsDv4Uv",
    "EC35OoQjuklK",
    "groaqP6RCF-A",
    "OYRFGJGh2nDy",
    "deJvvQSrbimP",
    "vxtpI00D3_XH",
    "q1LiE4Wozj5z",
    "kM95lYiZ0fs7",
    "zGoh-ohYQ2Fv",
    "cKr6k1Lrf7GH",
    "oZrZKvSAiSAS",
    "eyV6eVAhwLeh",
    "2MgExL7KApOC",
    "ub1SSn-OAvOb",
    "K15Vv3vpGQpl",
    "e0IKtbZyGCjS",
    "ibjc40sgHM55",
    "dWtzrmPeTsSN",
    "buA7D_4PdLeh"
   ],
   "name": "Module-1-Lab-cuda-python-numba.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
