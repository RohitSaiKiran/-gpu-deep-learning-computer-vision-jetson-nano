{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQdhXWtgOytW"
   },
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "y9O5kt_HLZkB"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Yw21jaaVNFCb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fa9863c78>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)  # reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IICvAEI9PMGa"
   },
   "source": [
    "# Training settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "xon9OoFpNJ-h"
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "e_geV-IKNLmF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--epochs'], dest='epochs', nargs=None, const=None, default=1000, type=<class 'int'>, choices=None, help='number of training epochs', metavar=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.add_argument('--data', default='data/weather.csv', type=str)\n",
    "parser.add_argument('--history', default=8, type=int, help='sequence history (in hours)')\n",
    "parser.add_argument('--horizon', default=1, type=int, help='forecasting horizon (in hours)')\n",
    "parser.add_argument('--split', default=0.8, type=float, help='train/test dataset split')\n",
    "parser.add_argument('--scaler', default='minmax', choices=['none', 'minmax', 'standard'], help='dataset preprocessing scaler to use')\n",
    "parser.add_argument('--lr', '--learning-rate', default=0.05, type=float, help='learning rate')\n",
    "parser.add_argument('--epochs', default=1000, type=int, help='number of training epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "pt_B-7Dp1km9"
   },
   "outputs": [],
   "source": [
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "M2OFjEbXNNP9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(data='data/weather.csv', epochs=1000, history=8, horizon=1, lr=0.05, scaler='minmax', split=0.8)\n"
     ]
    }
   ],
   "source": [
    "args = parser.parse_args(args=[])\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E58ChcNTPSC2"
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "wmxBd5ctNREE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data/weather.csv\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "print(f\"loading {args.data}\")\n",
    "df = pd.read_csv(args.data, parse_dates=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "gOapNtKeNTEb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       temperature\n",
      "0        52.592390\n",
      "1        52.588712\n",
      "2        52.585034\n",
      "3        52.581356\n",
      "4        52.577678\n",
      "...            ...\n",
      "40619    55.922000\n",
      "40620    58.496000\n",
      "40621    59.486000\n",
      "40622    59.900000\n",
      "40623    58.748000\n",
      "\n",
      "[40624 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "df = df[['temperature']]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c5rECBsoPUtn"
   },
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "yczjm8wvNt-F"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.27535059]\n",
      " [0.27528451]\n",
      " [0.27521844]\n",
      " ...\n",
      " [0.39919159]\n",
      " [0.40662894]\n",
      " [0.38593371]]\n",
      "(40624, 1)\n"
     ]
    }
   ],
   "source": [
    "# pre-process data\n",
    "if args.scaler == 'minmax':\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "elif args.scaler == 'standard':\n",
    "    scaler = StandardScaler()\n",
    "else:\n",
    "    scaler = None\n",
    "\n",
    "if scaler:\n",
    "    data = scaler.fit_transform(df.values)\n",
    "else:\n",
    "    data = df.values\n",
    "    \n",
    "print(data)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BA0iijShPXza"
   },
   "source": [
    "# Create PyTorch datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "1beRP84kNwP2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train torch.Size([32490, 8, 1])\n",
      "y_train torch.Size([32490, 1])\n",
      "x_test torch.Size([8116, 8, 1])\n",
      "y_test torch.Size([8116, 1])\n"
     ]
    }
   ],
   "source": [
    "# create PyTorch datasets\n",
    "def to_pytorch(array):\n",
    "    return torch.from_numpy(array).type(torch.FloatTensor).cuda()\n",
    "\n",
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "    \n",
    "def unscale(array, resize=None):\n",
    "    if not scaler: return array\n",
    "    if len(array.shape) == 0: array = array.reshape(-1, 1)\n",
    "    if len(array.shape) == 1: array = np.expand_dims(array, 0)\n",
    "    #if resize: array = np.concatenate((np.zeros((resize[0], resize[1]-1)), array), axis=1)\n",
    "    array = scaler.inverse_transform(array)\n",
    "    #return array[:,-1] if resize else array\n",
    "    return array\n",
    "    \n",
    "def generate_sequences(data, sequence_length):\n",
    "    if sequence_length == 1:\n",
    "        return np.expand_dims(data,1)\n",
    "    seq = []\n",
    "    for index in range(len(data) - sequence_length): \n",
    "        seq.append(data[index : index + sequence_length]) \n",
    "    return np.array(seq)\n",
    "            \n",
    "def create_dataset(data, history, horizon):\n",
    "    # shift the data by the forecast length\n",
    "    x = data[:-horizon,:]\n",
    "    y = np.roll(data[:,-1],-horizon,axis=0)[:-horizon]\n",
    "    \n",
    "    # generate sequences\n",
    "    x = generate_sequences(x, history)\n",
    "    y = generate_sequences(y, history)[:,-1]\n",
    "    \n",
    "    # cast to pytorch tensors\n",
    "    x = to_pytorch(x)\n",
    "    y = to_pytorch(y).unsqueeze(dim=-1)\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "train_split = int(len(data) * args.split)\n",
    "\n",
    "x_train, y_train = create_dataset(data[:train_split,:], args.history, args.horizon)\n",
    "x_test, y_test = create_dataset(data[train_split:,:], args.history, args.horizon)\n",
    " \n",
    "print('x_train', x_train.shape)\n",
    "print('y_train', y_train.shape)\n",
    "\n",
    "print('x_test', x_test.shape)\n",
    "print('y_test', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MgFrB2SZPefH"
   },
   "source": [
    "# Create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "CHpRG0KWN0BH"
   },
   "outputs": [],
   "source": [
    "# create model\n",
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_dim=1, output_dim=1, hidden_dim=32, num_layers=2):\n",
    "        super(GRU, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, num_layers, batch_first=True, dropout=0.0)\n",
    "        self.fc1 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_().cuda()\n",
    "        # UserWarning: RNN module weights are not part of single contiguous chunk of memory\n",
    "        #self.gru.flatten_parameters()   \n",
    "        x, (hn) = self.gru(x, (h0.detach()))\n",
    "        x = self.fc1(x[:, -1, :]) \n",
    "        return x\n",
    "\n",
    "net = GRU(x_train.shape[-1], 1).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aoWg7FJIPh1v"
   },
   "source": [
    "# Create a loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "snrd8HHGOfbI"
   },
   "outputs": [],
   "source": [
    "# create loss function and solver\n",
    "criterion = torch.nn.MSELoss().cuda()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=args.lr)  \n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 250, 0.5)\n",
    "\n",
    "def RMSE(y_pred, y):\n",
    "    return math.sqrt((np.square(unscale(to_numpy(y_pred)) - unscale(to_numpy(y)))).mean(axis=0).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lsiAHD0vPrRW"
   },
   "source": [
    "# Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "iQsj5XIaOhbw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000  LR=0.05  train_loss=0.05489146  test_loss=1.43279862  train_rmse=13.04171223  test_err=66.63076752\n",
      "Epoch 001  LR=0.05  train_loss=1.33856404  test_loss=0.14409821  train_rmse=64.40236069  test_err=21.13058488\n",
      "Epoch 002  LR=0.05  train_loss=0.15103596  test_loss=0.08149632  train_rmse=21.63328226  test_err=15.89099997\n",
      "Epoch 003  LR=0.05  train_loss=0.08006199  test_loss=0.05095008  train_rmse=15.75053865  test_err=12.56477419\n",
      "Epoch 004  LR=0.05  train_loss=0.04128540  test_loss=0.04803786  train_rmse=11.31046576  test_err=12.20040007\n",
      "Epoch 005  LR=0.05  train_loss=0.03166641  test_loss=0.06226980  train_rmse=9.90562076  test_err=13.89059809\n",
      "Epoch 006  LR=0.05  train_loss=0.04089048  test_loss=0.05386540  train_rmse=11.25623979  test_err=12.91924498\n",
      "Epoch 007  LR=0.05  train_loss=0.03482650  test_loss=0.04029753  train_rmse=10.38812455  test_err=11.17432911\n",
      "Epoch 008  LR=0.05  train_loss=0.03045428  test_loss=0.04020616  train_rmse=9.71418562  test_err=11.16165364\n",
      "Epoch 009  LR=0.05  train_loss=0.03651137  test_loss=0.02520608  train_rmse=10.63644080  test_err=8.83761071\n",
      "Epoch 010  LR=0.05  train_loss=0.01799196  test_loss=0.02922535  train_rmse=7.46657489  test_err=9.51616698\n",
      "Epoch 011  LR=0.05  train_loss=0.02071531  test_loss=0.01377489  train_rmse=8.01175970  test_err=6.53320604\n",
      "Epoch 012  LR=0.05  train_loss=0.00922706  test_loss=0.00711813  train_rmse=5.34704560  test_err=4.69640024\n",
      "Epoch 013  LR=0.05  train_loss=0.00707393  test_loss=0.05526933  train_rmse=4.68179890  test_err=13.08652517\n",
      "Epoch 014  LR=0.05  train_loss=0.06043533  test_loss=0.02155228  train_rmse=13.68446017  test_err=8.17200944\n",
      "Epoch 015  LR=0.05  train_loss=0.02113369  test_loss=0.03810702  train_rmse=8.09226098  test_err=10.86637519\n",
      "Epoch 016  LR=0.05  train_loss=0.03873372  test_loss=0.00227416  train_rmse=10.95536557  test_err=2.65456301\n",
      "Epoch 017  LR=0.05  train_loss=0.00237838  test_loss=0.01843684  train_rmse=2.71470517  test_err=7.55832248\n",
      "Epoch 018  LR=0.05  train_loss=0.01889641  test_loss=0.01815710  train_rmse=7.65194594  test_err=7.50076290\n",
      "Epoch 019  LR=0.05  train_loss=0.01756290  test_loss=0.01104152  train_rmse=7.37700871  test_err=5.84920374\n",
      "Epoch 020  LR=0.05  train_loss=0.00995902  test_loss=0.00883503  train_rmse=5.55508151  test_err=5.23222321\n",
      "Epoch 021  LR=0.05  train_loss=0.00846353  test_loss=0.01021905  train_rmse=5.12103695  test_err=5.62713633\n",
      "Epoch 022  LR=0.05  train_loss=0.01059307  test_loss=0.00412882  train_rmse=5.72918816  test_err=3.57680344\n",
      "Epoch 023  LR=0.05  train_loss=0.00404207  test_loss=0.00403051  train_rmse=3.53902720  test_err=3.53396610\n",
      "Epoch 024  LR=0.05  train_loss=0.00403826  test_loss=0.00671038  train_rmse=3.53735890  test_err=4.55990652\n",
      "Epoch 025  LR=0.05  train_loss=0.00723836  test_loss=0.00212924  train_rmse=4.73589842  test_err=2.56858977\n",
      "Epoch 026  LR=0.05  train_loss=0.00214000  test_loss=0.00548264  train_rmse=2.57507301  test_err=4.12170510\n",
      "Epoch 027  LR=0.05  train_loss=0.00540989  test_loss=0.00615341  train_rmse=4.09427133  test_err=4.36656815\n",
      "Epoch 028  LR=0.05  train_loss=0.00603373  test_loss=0.00234274  train_rmse=4.32389653  test_err=2.69428683\n",
      "Epoch 029  LR=0.05  train_loss=0.00217706  test_loss=0.00431120  train_rmse=2.59727184  test_err=3.65494834\n",
      "Epoch 030  LR=0.05  train_loss=0.00464540  test_loss=0.00281321  train_rmse=3.79397095  test_err=2.95245725\n",
      "Epoch 031  LR=0.05  train_loss=0.00307501  test_loss=0.00142716  train_rmse=3.08677658  test_err=2.10289691\n",
      "Epoch 032  LR=0.05  train_loss=0.00155728  test_loss=0.00320618  train_rmse=2.19667299  test_err=3.15192608\n",
      "Epoch 033  LR=0.05  train_loss=0.00351810  test_loss=0.00281115  train_rmse=3.30169181  test_err=2.95137158\n",
      "Epoch 034  LR=0.05  train_loss=0.00303958  test_loss=0.00174370  train_rmse=3.06894551  test_err=2.32443652\n",
      "Epoch 035  LR=0.05  train_loss=0.00177329  test_loss=0.00272349  train_rmse=2.34407763  test_err=2.90499506\n",
      "Epoch 036  LR=0.05  train_loss=0.00279261  test_loss=0.00268942  train_rmse=2.94162315  test_err=2.88676318\n",
      "Epoch 037  LR=0.05  train_loss=0.00279063  test_loss=0.00143182  train_rmse=2.94058325  test_err=2.10633246\n",
      "Epoch 038  LR=0.05  train_loss=0.00150308  test_loss=0.00175038  train_rmse=2.15810514  test_err=2.32889007\n",
      "Epoch 039  LR=0.05  train_loss=0.00194800  test_loss=0.00199329  train_rmse=2.45683678  test_err=2.48523337\n",
      "Epoch 040  LR=0.05  train_loss=0.00226367  test_loss=0.00114106  train_rmse=2.64843327  test_err=1.88034054\n",
      "Epoch 041  LR=0.05  train_loss=0.00133341  test_loss=0.00137705  train_rmse=2.03265978  test_err=2.06565246\n",
      "Epoch 042  LR=0.05  train_loss=0.00160426  test_loss=0.00180605  train_rmse=2.22955956  test_err=2.36563392\n",
      "Epoch 043  LR=0.05  train_loss=0.00208848  test_loss=0.00115569  train_rmse=2.54388280  test_err=1.89235362\n",
      "Epoch 044  LR=0.05  train_loss=0.00137458  test_loss=0.00132922  train_rmse=2.06379913  test_err=2.02946370\n",
      "Epoch 045  LR=0.05  train_loss=0.00158389  test_loss=0.00152801  train_rmse=2.21536017  test_err=2.17593181\n",
      "Epoch 046  LR=0.05  train_loss=0.00181933  test_loss=0.00100965  train_rmse=2.37431285  test_err=1.76875379\n",
      "Epoch 047  LR=0.05  train_loss=0.00123669  test_loss=0.00114760  train_rmse=1.95755150  test_err=1.88572050\n",
      "Epoch 048  LR=0.05  train_loss=0.00135672  test_loss=0.00135071  train_rmse=2.05034908  test_err=2.04580276\n",
      "Epoch 049  LR=0.05  train_loss=0.00154402  test_loss=0.00103187  train_rmse=2.18730468  test_err=1.78810814\n",
      "Epoch 050  LR=0.05  train_loss=0.00117238  test_loss=0.00117215  train_rmse=1.90597044  test_err=1.90578543\n",
      "Epoch 051  LR=0.05  train_loss=0.00132490  test_loss=0.00132765  train_rmse=2.02615775  test_err=2.02826025\n",
      "Epoch 052  LR=0.05  train_loss=0.00148470  test_loss=0.00111219  train_rmse=2.14487587  test_err=1.85640068\n",
      "Epoch 053  LR=0.05  train_loss=0.00121776  test_loss=0.00118620  train_rmse=1.94250997  test_err=1.91717084\n",
      "Epoch 054  LR=0.05  train_loss=0.00127933  test_loss=0.00125612  train_rmse=1.99101360  test_err=1.97286436\n",
      "Epoch 055  LR=0.05  train_loss=0.00137195  test_loss=0.00100294  train_rmse=2.06182573  test_err=1.76286451\n",
      "Epoch 056  LR=0.05  train_loss=0.00113795  test_loss=0.00100625  train_rmse=1.87777905  test_err=1.76577691\n",
      "Epoch 057  LR=0.05  train_loss=0.00118661  test_loss=0.00104954  train_rmse=1.91750652  test_err=1.80335579\n",
      "Epoch 058  LR=0.05  train_loss=0.00125612  test_loss=0.00091144  train_rmse=1.97286896  test_err=1.68052674\n",
      "Epoch 059  LR=0.05  train_loss=0.00110494  test_loss=0.00098041  train_rmse=1.85033837  test_err=1.74295301\n",
      "Epoch 060  LR=0.05  train_loss=0.00117767  test_loss=0.00101677  train_rmse=1.91026396  test_err=1.77498233\n",
      "Epoch 061  LR=0.05  train_loss=0.00121876  test_loss=0.00090736  train_rmse=1.94330687  test_err=1.67676656\n",
      "Epoch 062  LR=0.05  train_loss=0.00110222  test_loss=0.00096022  train_rmse=1.84806113  test_err=1.72491383\n",
      "Epoch 063  LR=0.05  train_loss=0.00116304  test_loss=0.00095711  train_rmse=1.89836541  test_err=1.72211446\n",
      "Epoch 064  LR=0.05  train_loss=0.00115556  test_loss=0.00089433  train_rmse=1.89225081  test_err=1.66467969\n",
      "Epoch 065  LR=0.05  train_loss=0.00107520  test_loss=0.00096022  train_rmse=1.82526755  test_err=1.72491141\n",
      "Epoch 066  LR=0.05  train_loss=0.00113550  test_loss=0.00095423  train_rmse=1.87575433  test_err=1.71952393\n",
      "Epoch 067  LR=0.05  train_loss=0.00112298  test_loss=0.00091548  train_rmse=1.86538565  test_err=1.68424625\n",
      "Epoch 068  LR=0.05  train_loss=0.00108220  test_loss=0.00095747  train_rmse=1.83120214  test_err=1.72244351\n",
      "Epoch 069  LR=0.05  train_loss=0.00113218  test_loss=0.00093396  train_rmse=1.87300678  test_err=1.70116592\n",
      "Epoch 070  LR=0.05  train_loss=0.00110668  test_loss=0.00090824  train_rmse=1.85179253  test_err=1.67758032\n",
      "Epoch 071  LR=0.05  train_loss=0.00107777  test_loss=0.00093344  train_rmse=1.82744755  test_err=1.70068913\n",
      "Epoch 072  LR=0.05  train_loss=0.00110894  test_loss=0.00089858  train_rmse=1.85368985  test_err=1.66863257\n",
      "Epoch 073  LR=0.05  train_loss=0.00107787  test_loss=0.00088504  train_rmse=1.82753568  test_err=1.65601491\n",
      "Epoch 074  LR=0.05  train_loss=0.00106987  test_loss=0.00090327  train_rmse=1.82073891  test_err=1.67298318\n",
      "Epoch 075  LR=0.05  train_loss=0.00109348  test_loss=0.00087913  train_rmse=1.84071987  test_err=1.65047838\n",
      "Epoch 076  LR=0.05  train_loss=0.00106752  test_loss=0.00088425  train_rmse=1.81873453  test_err=1.65527581\n",
      "Epoch 077  LR=0.05  train_loss=0.00107274  test_loss=0.00089190  train_rmse=1.82318288  test_err=1.66242112\n",
      "Epoch 078  LR=0.05  train_loss=0.00108078  test_loss=0.00087035  train_rmse=1.82999579  test_err=1.64221354\n",
      "Epoch 079  LR=0.05  train_loss=0.00105696  test_loss=0.00087973  train_rmse=1.80972084  test_err=1.65103812\n",
      "Epoch 080  LR=0.05  train_loss=0.00106678  test_loss=0.00087983  train_rmse=1.81811089  test_err=1.65113480\n",
      "Epoch 081  LR=0.05  train_loss=0.00106399  test_loss=0.00087382  train_rmse=1.81572620  test_err=1.64548463\n",
      "Epoch 082  LR=0.05  train_loss=0.00105172  test_loss=0.00089011  train_rmse=1.80522940  test_err=1.66075256\n",
      "Epoch 083  LR=0.05  train_loss=0.00106420  test_loss=0.00088513  train_rmse=1.81590635  test_err=1.65610151\n",
      "Epoch 084  LR=0.05  train_loss=0.00105661  test_loss=0.00088096  train_rmse=1.80941780  test_err=1.65219289\n",
      "Epoch 085  LR=0.05  train_loss=0.00105300  test_loss=0.00088592  train_rmse=1.80632744  test_err=1.65683844\n",
      "Epoch 086  LR=0.05  train_loss=0.00105948  test_loss=0.00087679  train_rmse=1.81187764  test_err=1.64827594\n",
      "Epoch 087  LR=0.05  train_loss=0.00104883  test_loss=0.00087889  train_rmse=1.80274376  test_err=1.65024840\n",
      "Epoch 088  LR=0.05  train_loss=0.00105047  test_loss=0.00087870  train_rmse=1.80415548  test_err=1.65007437\n",
      "Epoch 089  LR=0.05  train_loss=0.00105138  test_loss=0.00087029  train_rmse=1.80493823  test_err=1.64215547\n",
      "Epoch 090  LR=0.05  train_loss=0.00104451  test_loss=0.00087347  train_rmse=1.79903090  test_err=1.64515511\n",
      "Epoch 091  LR=0.05  train_loss=0.00104945  test_loss=0.00087138  train_rmse=1.80328110  test_err=1.64317864\n",
      "Epoch 092  LR=0.05  train_loss=0.00104604  test_loss=0.00087182  train_rmse=1.80034945  test_err=1.64359879\n",
      "Epoch 093  LR=0.05  train_loss=0.00104351  test_loss=0.00087676  train_rmse=1.79817140  test_err=1.64825164\n",
      "Epoch 094  LR=0.05  train_loss=0.00104594  test_loss=0.00087370  train_rmse=1.80026264  test_err=1.64537009\n",
      "Epoch 095  LR=0.05  train_loss=0.00104065  test_loss=0.00087619  train_rmse=1.79570653  test_err=1.64771121\n",
      "Epoch 096  LR=0.05  train_loss=0.00104171  test_loss=0.00087852  train_rmse=1.79662135  test_err=1.64989888\n",
      "Epoch 097  LR=0.05  train_loss=0.00104127  test_loss=0.00087974  train_rmse=1.79623548  test_err=1.65104549\n",
      "Epoch 098  LR=0.05  train_loss=0.00103851  test_loss=0.00088437  train_rmse=1.79385188  test_err=1.65538650\n",
      "Epoch 099  LR=0.05  train_loss=0.00104064  test_loss=0.00088233  train_rmse=1.79569099  test_err=1.65347309\n",
      "Epoch 100  LR=0.05  train_loss=0.00103810  test_loss=0.00088065  train_rmse=1.79350402  test_err=1.65189826\n",
      "Epoch 101  LR=0.05  train_loss=0.00103767  test_loss=0.00087986  train_rmse=1.79313071  test_err=1.65116137\n",
      "Epoch 102  LR=0.05  train_loss=0.00103782  test_loss=0.00087757  train_rmse=1.79326127  test_err=1.64900776\n",
      "Epoch 103  LR=0.05  train_loss=0.00103534  test_loss=0.00087810  train_rmse=1.79111553  test_err=1.64950578\n",
      "Epoch 104  LR=0.05  train_loss=0.00103621  test_loss=0.00087559  train_rmse=1.79187277  test_err=1.64714614\n",
      "Epoch 105  LR=0.05  train_loss=0.00103488  test_loss=0.00087338  train_rmse=1.79071628  test_err=1.64506562\n",
      "Epoch 106  LR=0.05  train_loss=0.00103422  test_loss=0.00087305  train_rmse=1.79014648  test_err=1.64475551\n",
      "Epoch 107  LR=0.05  train_loss=0.00103449  test_loss=0.00087230  train_rmse=1.79037874  test_err=1.64405007\n",
      "Epoch 108  LR=0.05  train_loss=0.00103277  test_loss=0.00087366  train_rmse=1.78889498  test_err=1.64533451\n",
      "Epoch 109  LR=0.05  train_loss=0.00103298  test_loss=0.00087323  train_rmse=1.78907176  test_err=1.64492858\n",
      "Epoch 110  LR=0.05  train_loss=0.00103195  test_loss=0.00087256  train_rmse=1.78817880  test_err=1.64429253\n",
      "Epoch 111  LR=0.05  train_loss=0.00103123  test_loss=0.00087293  train_rmse=1.78756051  test_err=1.64464070\n",
      "Epoch 112  LR=0.05  train_loss=0.00103126  test_loss=0.00087284  train_rmse=1.78758459  test_err=1.64455851\n",
      "Epoch 113  LR=0.05  train_loss=0.00103015  test_loss=0.00087349  train_rmse=1.78662056  test_err=1.64516765\n",
      "Epoch 114  LR=0.05  train_loss=0.00103022  test_loss=0.00087224  train_rmse=1.78668014  test_err=1.64399533\n",
      "Epoch 115  LR=0.05  train_loss=0.00102946  test_loss=0.00087043  train_rmse=1.78602569  test_err=1.64228606\n",
      "Epoch 116  LR=0.05  train_loss=0.00102891  test_loss=0.00086918  train_rmse=1.78554606  test_err=1.64111045\n",
      "Epoch 117  LR=0.05  train_loss=0.00102869  test_loss=0.00086797  train_rmse=1.78535210  test_err=1.63996423\n",
      "Epoch 118  LR=0.05  train_loss=0.00102784  test_loss=0.00086749  train_rmse=1.78461647  test_err=1.63950855\n",
      "Epoch 119  LR=0.05  train_loss=0.00102776  test_loss=0.00086611  train_rmse=1.78454459  test_err=1.63820935\n",
      "Epoch 120  LR=0.05  train_loss=0.00102712  test_loss=0.00086498  train_rmse=1.78399507  test_err=1.63713866\n",
      "Epoch 121  LR=0.05  train_loss=0.00102676  test_loss=0.00086453  train_rmse=1.78368245  test_err=1.63671511\n",
      "Epoch 122  LR=0.05  train_loss=0.00102643  test_loss=0.00086450  train_rmse=1.78339438  test_err=1.63668430\n",
      "Epoch 123  LR=0.05  train_loss=0.00102580  test_loss=0.00086489  train_rmse=1.78284905  test_err=1.63705470\n",
      "Epoch 124  LR=0.05  train_loss=0.00102559  test_loss=0.00086454  train_rmse=1.78266382  test_err=1.63672392\n",
      "Epoch 125  LR=0.05  train_loss=0.00102500  test_loss=0.00086432  train_rmse=1.78214971  test_err=1.63651750\n",
      "Epoch 126  LR=0.05  train_loss=0.00102472  test_loss=0.00086429  train_rmse=1.78190306  test_err=1.63648115\n",
      "Epoch 127  LR=0.05  train_loss=0.00102432  test_loss=0.00086437  train_rmse=1.78156050  test_err=1.63656259\n",
      "Epoch 128  LR=0.05  train_loss=0.00102389  test_loss=0.00086424  train_rmse=1.78118622  test_err=1.63643278\n",
      "Epoch 129  LR=0.05  train_loss=0.00102362  test_loss=0.00086338  train_rmse=1.78094808  test_err=1.63562172\n",
      "Epoch 130  LR=0.05  train_loss=0.00102312  test_loss=0.00086264  train_rmse=1.78051636  test_err=1.63492597\n",
      "Epoch 131  LR=0.05  train_loss=0.00102285  test_loss=0.00086209  train_rmse=1.78027987  test_err=1.63439952\n",
      "Epoch 132  LR=0.05  train_loss=0.00102242  test_loss=0.00086182  train_rmse=1.77990632  test_err=1.63414298\n",
      "Epoch 133  LR=0.05  train_loss=0.00102209  test_loss=0.00086140  train_rmse=1.77962158  test_err=1.63374207\n",
      "Epoch 134  LR=0.05  train_loss=0.00102177  test_loss=0.00086079  train_rmse=1.77933520  test_err=1.63317130\n",
      "Epoch 135  LR=0.05  train_loss=0.00102138  test_loss=0.00086052  train_rmse=1.77899790  test_err=1.63290953\n",
      "Epoch 136  LR=0.05  train_loss=0.00102109  test_loss=0.00086051  train_rmse=1.77874875  test_err=1.63290478\n",
      "Epoch 137  LR=0.05  train_loss=0.00102069  test_loss=0.00086069  train_rmse=1.77839767  test_err=1.63307108\n",
      "Epoch 138  LR=0.05  train_loss=0.00102040  test_loss=0.00086056  train_rmse=1.77814353  test_err=1.63295325\n",
      "Epoch 139  LR=0.05  train_loss=0.00102003  test_loss=0.00086033  train_rmse=1.77782754  test_err=1.63272846\n",
      "Epoch 140  LR=0.05  train_loss=0.00101972  test_loss=0.00086020  train_rmse=1.77755367  test_err=1.63260427\n",
      "Epoch 141  LR=0.05  train_loss=0.00101941  test_loss=0.00086013  train_rmse=1.77727990  test_err=1.63254322\n",
      "Epoch 142  LR=0.05  train_loss=0.00101907  test_loss=0.00085992  train_rmse=1.77698455  test_err=1.63234452\n",
      "Epoch 143  LR=0.05  train_loss=0.00101878  test_loss=0.00085938  train_rmse=1.77673074  test_err=1.63183375\n",
      "Epoch 144  LR=0.05  train_loss=0.00101843  test_loss=0.00085886  train_rmse=1.77643040  test_err=1.63134013\n",
      "Epoch 145  LR=0.05  train_loss=0.00101815  test_loss=0.00085850  train_rmse=1.77618041  test_err=1.63098941\n",
      "Epoch 146  LR=0.05  train_loss=0.00101782  test_loss=0.00085825  train_rmse=1.77589616  test_err=1.63075879\n",
      "Epoch 147  LR=0.05  train_loss=0.00101753  test_loss=0.00085790  train_rmse=1.77564166  test_err=1.63042732\n",
      "Epoch 148  LR=0.05  train_loss=0.00101722  test_loss=0.00085751  train_rmse=1.77537713  test_err=1.63005015\n",
      "Epoch 149  LR=0.05  train_loss=0.00101692  test_loss=0.00085728  train_rmse=1.77511349  test_err=1.62983139\n",
      "Epoch 150  LR=0.05  train_loss=0.00101663  test_loss=0.00085721  train_rmse=1.77486144  test_err=1.62976754\n",
      "Epoch 151  LR=0.05  train_loss=0.00101633  test_loss=0.00085714  train_rmse=1.77459417  test_err=1.62970368\n",
      "Epoch 152  LR=0.05  train_loss=0.00101605  test_loss=0.00085691  train_rmse=1.77435031  test_err=1.62947837\n",
      "Epoch 153  LR=0.05  train_loss=0.00101575  test_loss=0.00085665  train_rmse=1.77408860  test_err=1.62923335\n",
      "Epoch 154  LR=0.05  train_loss=0.00101547  test_loss=0.00085645  train_rmse=1.77384783  test_err=1.62905027\n",
      "Epoch 155  LR=0.05  train_loss=0.00101518  test_loss=0.00085627  train_rmse=1.77359438  test_err=1.62887676\n",
      "Epoch 156  LR=0.05  train_loss=0.00101491  test_loss=0.00085595  train_rmse=1.77335213  test_err=1.62856606\n",
      "Epoch 157  LR=0.05  train_loss=0.00101462  test_loss=0.00085552  train_rmse=1.77310682  test_err=1.62816268\n",
      "Epoch 158  LR=0.05  train_loss=0.00101435  test_loss=0.00085517  train_rmse=1.77286362  test_err=1.62782497\n",
      "Epoch 159  LR=0.05  train_loss=0.00101407  test_loss=0.00085491  train_rmse=1.77262631  test_err=1.62758094\n",
      "Epoch 160  LR=0.05  train_loss=0.00101380  test_loss=0.00085466  train_rmse=1.77238534  test_err=1.62733790\n",
      "Epoch 161  LR=0.05  train_loss=0.00101353  test_loss=0.00085434  train_rmse=1.77215348  test_err=1.62703438\n",
      "Epoch 162  LR=0.05  train_loss=0.00101326  test_loss=0.00085407  train_rmse=1.77191514  test_err=1.62677734\n",
      "Epoch 163  LR=0.05  train_loss=0.00101300  test_loss=0.00085390  train_rmse=1.77168597  test_err=1.62661861\n",
      "Epoch 164  LR=0.05  train_loss=0.00101273  test_loss=0.00085377  train_rmse=1.77145147  test_err=1.62649108\n",
      "Epoch 165  LR=0.05  train_loss=0.00101247  test_loss=0.00085355  train_rmse=1.77122433  test_err=1.62628622\n",
      "Epoch 166  LR=0.05  train_loss=0.00101221  test_loss=0.00085329  train_rmse=1.77099515  test_err=1.62603705\n",
      "Epoch 167  LR=0.05  train_loss=0.00101195  test_loss=0.00085306  train_rmse=1.77077005  test_err=1.62582113\n",
      "Epoch 168  LR=0.05  train_loss=0.00101170  test_loss=0.00085286  train_rmse=1.77054525  test_err=1.62562468\n",
      "Epoch 169  LR=0.05  train_loss=0.00101144  test_loss=0.00085259  train_rmse=1.77032197  test_err=1.62536866\n",
      "Epoch 170  LR=0.05  train_loss=0.00101119  test_loss=0.00085226  train_rmse=1.77010109  test_err=1.62505208\n",
      "Epoch 171  LR=0.05  train_loss=0.00101093  test_loss=0.00085195  train_rmse=1.76988005  test_err=1.62476391\n",
      "Epoch 172  LR=0.05  train_loss=0.00101069  test_loss=0.00085171  train_rmse=1.76966261  test_err=1.62453359\n",
      "Epoch 173  LR=0.05  train_loss=0.00101044  test_loss=0.00085148  train_rmse=1.76944455  test_err=1.62430800\n",
      "Epoch 174  LR=0.05  train_loss=0.00101019  test_loss=0.00085120  train_rmse=1.76923016  test_err=1.62404950\n",
      "Epoch 175  LR=0.05  train_loss=0.00100995  test_loss=0.00085096  train_rmse=1.76901487  test_err=1.62381143\n",
      "Epoch 176  LR=0.05  train_loss=0.00100970  test_loss=0.00085076  train_rmse=1.76880299  test_err=1.62362745\n",
      "Epoch 177  LR=0.05  train_loss=0.00100946  test_loss=0.00085058  train_rmse=1.76859061  test_err=1.62345483\n",
      "Epoch 178  LR=0.05  train_loss=0.00100922  test_loss=0.00085035  train_rmse=1.76838118  test_err=1.62323702\n",
      "Epoch 179  LR=0.05  train_loss=0.00100898  test_loss=0.00085010  train_rmse=1.76817185  test_err=1.62299627\n",
      "Epoch 180  LR=0.05  train_loss=0.00100875  test_loss=0.00084987  train_rmse=1.76796486  test_err=1.62277539\n",
      "Epoch 181  LR=0.05  train_loss=0.00100851  test_loss=0.00084964  train_rmse=1.76775839  test_err=1.62255984\n",
      "Epoch 182  LR=0.05  train_loss=0.00100828  test_loss=0.00084938  train_rmse=1.76755364  test_err=1.62230591\n",
      "Epoch 183  LR=0.05  train_loss=0.00100805  test_loss=0.00084909  train_rmse=1.76734989  test_err=1.62202651\n",
      "Epoch 184  LR=0.05  train_loss=0.00100782  test_loss=0.00084882  train_rmse=1.76714745  test_err=1.62177036\n",
      "Epoch 185  LR=0.05  train_loss=0.00100759  test_loss=0.00084858  train_rmse=1.76694642  test_err=1.62154189\n",
      "Epoch 186  LR=0.05  train_loss=0.00100736  test_loss=0.00084833  train_rmse=1.76674630  test_err=1.62130515\n",
      "Epoch 187  LR=0.05  train_loss=0.00100713  test_loss=0.00084807  train_rmse=1.76654771  test_err=1.62105404\n",
      "Epoch 188  LR=0.05  train_loss=0.00100691  test_loss=0.00084783  train_rmse=1.76634998  test_err=1.62082282\n",
      "Epoch 189  LR=0.05  train_loss=0.00100668  test_loss=0.00084761  train_rmse=1.76615378  test_err=1.62061716\n",
      "Epoch 190  LR=0.05  train_loss=0.00100646  test_loss=0.00084739  train_rmse=1.76595837  test_err=1.62040243\n",
      "Epoch 191  LR=0.05  train_loss=0.00100624  test_loss=0.00084713  train_rmse=1.76576448  test_err=1.62016192\n",
      "Epoch 192  LR=0.05  train_loss=0.00100602  test_loss=0.00084688  train_rmse=1.76557126  test_err=1.61992152\n",
      "Epoch 193  LR=0.05  train_loss=0.00100580  test_loss=0.00084665  train_rmse=1.76537963  test_err=1.61969412\n",
      "Epoch 194  LR=0.05  train_loss=0.00100558  test_loss=0.00084640  train_rmse=1.76518879  test_err=1.61945865\n",
      "Epoch 195  LR=0.05  train_loss=0.00100537  test_loss=0.00084613  train_rmse=1.76499928  test_err=1.61920188\n",
      "Epoch 196  LR=0.05  train_loss=0.00100515  test_loss=0.00084587  train_rmse=1.76481063  test_err=1.61894772\n",
      "Epoch 197  LR=0.05  train_loss=0.00100494  test_loss=0.00084562  train_rmse=1.76462337  test_err=1.61871435\n",
      "Epoch 198  LR=0.05  train_loss=0.00100473  test_loss=0.00084538  train_rmse=1.76443691  test_err=1.61848685\n",
      "Epoch 199  LR=0.05  train_loss=0.00100452  test_loss=0.00084514  train_rmse=1.76425172  test_err=1.61825025\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "MAX_EPOCHS = 200  # or any cap you'd like\n",
    "args.epochs = min(args.epochs, MAX_EPOCHS)\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "    net.train()\n",
    "    \n",
    "    y_pred = net(x_train)\n",
    "    train_loss = criterion(y_pred, y_train)\n",
    "    train_rmse = RMSE(y_pred, y_train)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    \n",
    "    net.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        y_pred = net(x_test)\n",
    "        test_loss = criterion(y_pred, y_test)\n",
    "        test_rmse = RMSE(y_pred, y_test)\n",
    "        #unscaled_loss = unscale(np.array(loss.item())).item()\n",
    "        #unscaled_test_loss = unscale(np.array(test_loss.item())).item()\n",
    "        print(f\"Epoch {epoch:03d}  LR={scheduler.get_last_lr()[0]}  train_loss={train_loss:.8f}  test_loss={test_loss:.8f}  train_rmse={train_rmse:.8f}  test_err={test_rmse:.8f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-AfpM2luPxs8"
   },
   "source": [
    "# Print out actual vs predicted values   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "yr0GeSqDOjeG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "y_test [[40.82    ]\n",
      " [43.07    ]\n",
      " [44.852   ]\n",
      " ...\n",
      " [58.496   ]\n",
      " [59.485996]\n",
      " [59.899998]]\n",
      "y_pred [[40.78715 ]\n",
      " [41.264645]\n",
      " [43.668705]\n",
      " ...\n",
      " [57.370827]\n",
      " [59.271862]\n",
      " [59.845745]]\n"
     ]
    }
   ],
   "source": [
    "# print out actual vs predicted values     \n",
    "#x_test = to_numpy(x_test)\n",
    "y_test = to_numpy(y_test)\n",
    "y_pred = to_numpy(y_pred)\n",
    " \n",
    "if scaler:\n",
    "    #x_test = unscale(x_test)\n",
    "    y_test = unscale(y_test, x_test.shape)\n",
    "    y_pred = unscale(y_pred, x_test.shape)\n",
    "\n",
    "print('')\n",
    "#print('x_test', x_test)\n",
    "print('y_test', y_test)\n",
    "print('y_pred', y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "P15FJj7eu5qF"
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Use non-GUI backend\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Flatten the arrays (if needed)\n",
    "y_test_flat = y_test.flatten()\n",
    "y_pred_flat = y_pred.flatten()\n",
    "\n",
    "# Generate index or time steps for the x-axis\n",
    "x = np.arange(len(y_test_flat))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(x, y_test_flat, label='Actual', color='blue')\n",
    "plt.plot(x, y_pred_flat, label='Predicted', color='orange')\n",
    "plt.title('Actual vs Predicted Values')\n",
    "plt.xlabel('Time Step / Sample Index')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('actual_vs_predicted.png')  # You can change the filename and format\n",
    "plt.close()  # Close the figure to free memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: data/ (stored 0%)\n",
      "  adding: data/.ipynb_checkpoints/ (stored 0%)\n",
      "  adding: data/.ipynb_checkpoints/solar_power-checkpoint.csv (deflated 62%)\n",
      "  adding: data/.ipynb_checkpoints/solar_power-checkpoint.jpg (deflated 14%)\n",
      "  adding: data/.ipynb_checkpoints/shuttle-checkpoint.csv (deflated 72%)\n",
      "  adding: data/weather.jpg (deflated 10%)\n",
      "  adding: data/solar_power.jpg (deflated 14%)\n",
      "  adding: data/weather_temperature.jpg (deflated 14%)\n",
      "  adding: data/weather.csv (deflated 76%)\n",
      "  adding: data/solar_power.csv (deflated 62%)\n",
      "  adding: data/shuttle.csv (deflated 72%)\n",
      "  adding: Module-1-Lab-solar-power-pred.py (deflated 44%)\n",
      "  adding: .ipynb_checkpoints/ (stored 0%)\n",
      "  adding: .ipynb_checkpoints/Module-1-Lab-space-shuttle-class-checkpoint.ipynb (deflated 75%)\n",
      "  adding: .ipynb_checkpoints/Module-1-Lab-weather-pred-hand-coded-checkpoint.ipynb (deflated 76%)\n",
      "  adding: .ipynb_checkpoints/Module-1-Lab-weather-pred-checkpoint.ipynb (deflated 37%)\n",
      "  adding: .ipynb_checkpoints/Module-1-Lab-solar-power-pred-checkpoint.ipynb (deflated 42%)\n",
      "  adding: Module-1-Lab-weather-pred-hand-coded.py (deflated 62%)\n",
      "  adding: Module-1-Lab-solar-power-pred.html (deflated 84%)\n",
      "  adding: Module-1-Lab-space-shuttle-class.html (deflated 84%)\n",
      "  adding: Module-1-Lab-weather-pred-hand-coded.html (deflated 85%)\n",
      "  adding: pytorch-timeseries/ (stored 0%)\n",
      "  adding: pytorch-timeseries/data/ (stored 0%)\n",
      "  adding: pytorch-timeseries/data/weather.jpg (deflated 10%)\n",
      "  adding: pytorch-timeseries/data/solar_power.jpg (deflated 14%)\n",
      "  adding: pytorch-timeseries/data/weather_temperature.jpg (deflated 14%)\n",
      "  adding: pytorch-timeseries/data/weather.csv (deflated 82%)\n",
      "  adding: pytorch-timeseries/data/solar_power.csv (deflated 67%)\n",
      "  adding: pytorch-timeseries/data/shuttle.csv (deflated 72%)\n",
      "  adding: pytorch-timeseries/scripts/ (stored 0%)\n",
      "  adding: pytorch-timeseries/scripts/prepare_shuttle.py (deflated 52%)\n",
      "  adding: pytorch-timeseries/scripts/prepare_weather.py (deflated 50%)\n",
      "  adding: pytorch-timeseries/scripts/prepare_solar.py (deflated 53%)\n",
      "  adding: pytorch-timeseries/README.md (deflated 55%)\n",
      "  adding: pytorch-timeseries/train.py (deflated 65%)\n",
      "  adding: pytorch-timeseries/models/ (stored 0%)\n",
      "  adding: pytorch-timeseries/models/__init__.py (deflated 42%)\n",
      "  adding: pytorch-timeseries/models/gru.py (deflated 51%)\n",
      "  adding: pytorch-timeseries/models/.ipynb_checkpoints/ (stored 0%)\n",
      "  adding: pytorch-timeseries/models/.ipynb_checkpoints/gru-checkpoint.py (deflated 51%)\n",
      "  adding: pytorch-timeseries/models/linear.py (deflated 60%)\n",
      "  adding: pytorch-timeseries/models/__pycache__/ (stored 0%)\n",
      "  adding: pytorch-timeseries/models/__pycache__/gru.cpython-36.pyc (deflated 35%)\n",
      "  adding: pytorch-timeseries/models/__pycache__/__init__.cpython-36.pyc (deflated 25%)\n",
      "  adding: pytorch-timeseries/models/__pycache__/linear.cpython-36.pyc (deflated 39%)\n",
      "  adding: pytorch-timeseries/.git/ (stored 0%)\n",
      "  adding: pytorch-timeseries/.git/description (deflated 14%)\n",
      "  adding: pytorch-timeseries/.git/index (deflated 44%)\n",
      "  adding: pytorch-timeseries/.git/HEAD (stored 0%)\n",
      "  adding: pytorch-timeseries/.git/branches/ (stored 0%)\n",
      "  adding: pytorch-timeseries/.git/refs/ (stored 0%)\n",
      "  adding: pytorch-timeseries/.git/refs/heads/ (stored 0%)\n",
      "  adding: pytorch-timeseries/.git/refs/heads/main (stored 0%)\n",
      "  adding: pytorch-timeseries/.git/refs/remotes/ (stored 0%)\n",
      "  adding: pytorch-timeseries/.git/refs/remotes/origin/ (stored 0%)\n",
      "  adding: pytorch-timeseries/.git/refs/remotes/origin/HEAD (stored 0%)\n",
      "  adding: pytorch-timeseries/.git/refs/tags/ (stored 0%)\n",
      "  adding: pytorch-timeseries/.git/logs/ (stored 0%)\n",
      "  adding: pytorch-timeseries/.git/logs/HEAD (deflated 29%)\n",
      "  adding: pytorch-timeseries/.git/logs/refs/ (stored 0%)\n",
      "  adding: pytorch-timeseries/.git/logs/refs/heads/ (stored 0%)\n",
      "  adding: pytorch-timeseries/.git/logs/refs/heads/main (deflated 29%)\n",
      "  adding: pytorch-timeseries/.git/logs/refs/remotes/ (stored 0%)\n",
      "  adding: pytorch-timeseries/.git/logs/refs/remotes/origin/ (stored 0%)\n",
      "  adding: pytorch-timeseries/.git/logs/refs/remotes/origin/HEAD (deflated 29%)\n",
      "  adding: pytorch-timeseries/.git/info/ (stored 0%)\n",
      "  adding: pytorch-timeseries/.git/info/exclude (deflated 28%)\n",
      "  adding: pytorch-timeseries/.git/config (deflated 34%)\n",
      "  adding: pytorch-timeseries/.git/objects/ (stored 0%)\n",
      "  adding: pytorch-timeseries/.git/objects/info/ (stored 0%)\n",
      "  adding: pytorch-timeseries/.git/objects/pack/ (stored 0%)\n",
      "  adding: pytorch-timeseries/.git/objects/pack/pack-e629a10a0cebfa9051f78a170c5465f19d6a7320.pack (deflated 0%)\n",
      "  adding: pytorch-timeseries/.git/objects/pack/pack-e629a10a0cebfa9051f78a170c5465f19d6a7320.idx (deflated 17%)\n",
      "  adding: pytorch-timeseries/.git/packed-refs (deflated 9%)\n",
      "  adding: pytorch-timeseries/.git/hooks/ (stored 0%)\n",
      "  adding: pytorch-timeseries/.git/hooks/prepare-commit-msg.sample (deflated 50%)\n",
      "  adding: pytorch-timeseries/.git/hooks/post-update.sample (deflated 27%)\n",
      "  adding: pytorch-timeseries/.git/hooks/fsmonitor-watchman.sample (deflated 53%)\n",
      "  adding: pytorch-timeseries/.git/hooks/pre-commit.sample (deflated 43%)\n",
      "  adding: pytorch-timeseries/.git/hooks/pre-rebase.sample (deflated 59%)\n",
      "  adding: pytorch-timeseries/.git/hooks/pre-push.sample (deflated 50%)\n",
      "  adding: pytorch-timeseries/.git/hooks/commit-msg.sample (deflated 44%)\n",
      "  adding: pytorch-timeseries/.git/hooks/pre-applypatch.sample (deflated 38%)\n",
      "  adding: pytorch-timeseries/.git/hooks/applypatch-msg.sample (deflated 42%)\n",
      "  adding: pytorch-timeseries/.git/hooks/pre-receive.sample (deflated 40%)\n",
      "  adding: pytorch-timeseries/.git/hooks/update.sample (deflated 68%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/ (stored 0%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/data/ (stored 0%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/data/weather.jpg (deflated 10%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/data/solar_power.jpg (deflated 14%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/data/weather_temperature.jpg (deflated 14%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/data/weather.csv (deflated 82%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/data/solar_power.csv (deflated 67%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/data/shuttle.csv (deflated 72%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/scripts/ (stored 0%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/scripts/prepare_shuttle.py (deflated 52%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/scripts/prepare_weather.py (deflated 50%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/scripts/prepare_solar.py (deflated 53%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/README.md (deflated 55%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/train.py (deflated 65%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/models/ (stored 0%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/models/__init__.py (deflated 42%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/models/gru.py (deflated 51%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/models/linear.py (deflated 60%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/models/__pycache__/ (stored 0%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/models/__pycache__/gru.cpython-36.pyc (deflated 36%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/models/__pycache__/__init__.cpython-36.pyc (deflated 27%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/models/__pycache__/linear.cpython-36.pyc (deflated 40%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/.git/ (stored 0%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/.git/description (deflated 14%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/.git/index (deflated 44%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/.git/HEAD (stored 0%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/.git/branches/ (stored 0%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/.git/refs/ (stored 0%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/.git/refs/heads/ (stored 0%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/.git/refs/heads/main (stored 0%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/.git/refs/remotes/ (stored 0%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/.git/refs/remotes/origin/ (stored 0%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/.git/refs/remotes/origin/HEAD (stored 0%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/.git/refs/tags/ (stored 0%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/.git/logs/ (stored 0%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/.git/logs/HEAD (deflated 28%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/.git/logs/refs/ (stored 0%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/.git/logs/refs/heads/ (stored 0%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/.git/logs/refs/heads/main (deflated 28%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/.git/logs/refs/remotes/ (stored 0%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/.git/logs/refs/remotes/origin/ (stored 0%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/.git/logs/refs/remotes/origin/HEAD (deflated 28%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/.git/info/ (stored 0%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/.git/info/exclude (deflated 28%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/.git/config (deflated 34%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/.git/objects/ (stored 0%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/.git/objects/info/ (stored 0%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/.git/objects/pack/ (stored 0%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/.git/objects/pack/pack-e629a10a0cebfa9051f78a170c5465f19d6a7320.pack (deflated 0%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/.git/objects/pack/pack-e629a10a0cebfa9051f78a170c5465f19d6a7320.idx (deflated 17%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/.git/packed-refs (deflated 9%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/.git/hooks/ (stored 0%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/.git/hooks/prepare-commit-msg.sample (deflated 50%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/.git/hooks/post-update.sample (deflated 27%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/.git/hooks/fsmonitor-watchman.sample (deflated 53%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/.git/hooks/pre-commit.sample (deflated 43%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/.git/hooks/pre-rebase.sample (deflated 59%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/.git/hooks/pre-push.sample (deflated 50%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/.git/hooks/commit-msg.sample (deflated 44%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/.git/hooks/pre-applypatch.sample (deflated 38%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/.git/hooks/applypatch-msg.sample (deflated 42%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/.git/hooks/pre-receive.sample (deflated 40%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/.git/hooks/update.sample (deflated 68%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/dataset.py (deflated 74%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/weather.py (deflated 63%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/__pycache__/ (stored 0%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/__pycache__/model.cpython-36.pyc (deflated 48%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/__pycache__/dataset.cpython-36.pyc (deflated 54%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/model.py (deflated 71%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/docker/ (stored 0%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/docker/tag.sh (deflated 62%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/docker/l4t_version.sh (deflated 50%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/docker/run.sh (deflated 69%)\n",
      "  adding: pytorch-timeseries/pytorch-timeseries/.gitignore (deflated 46%)\n",
      "  adding: pytorch-timeseries/dataset.py (deflated 74%)\n",
      "  adding: pytorch-timeseries/weather.py (deflated 63%)\n",
      "  adding: pytorch-timeseries/__pycache__/ (stored 0%)\n",
      "  adding: pytorch-timeseries/__pycache__/model.cpython-36.pyc (deflated 48%)\n",
      "  adding: pytorch-timeseries/__pycache__/dataset.cpython-36.pyc (deflated 54%)\n",
      "  adding: pytorch-timeseries/model.py (deflated 71%)\n",
      "  adding: pytorch-timeseries/docker/ (stored 0%)\n",
      "  adding: pytorch-timeseries/docker/tag.sh (deflated 62%)\n",
      "  adding: pytorch-timeseries/docker/l4t_version.sh (deflated 50%)\n",
      "  adding: pytorch-timeseries/docker/run.sh (deflated 69%)\n",
      "  adding: pytorch-timeseries/.gitignore (deflated 46%)\n",
      "  adding: actual_vs_predicted.png (deflated 3%)\n",
      "  adding: Module-1-Lab-solar-power-pred.ipynb (deflated 42%)\n",
      "  adding: Module-1-Lab-weather-pred.ipynb (deflated 37%)\n",
      "  adding: Module-1-Lab-weather-pred-hand-coded.ipynb (deflated 76%)\n",
      "  adding: Module-1-Lab-space-shuttle-class.ipynb (deflated 75%)\n",
      "  adding: Module-1-Lab-weather-pred.html (deflated 84%)\n",
      "  adding: Module-1-Lab-space-shuttle-class.py (deflated 46%)\n",
      "  adding: Module-1-Lab-time-series-pytorch.docx (deflated 10%)\n",
      "  adding: Module-1-lab-weather-pred.py (deflated 50%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r ../Group17_Assignment.zip .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "RQdhXWtgOytW",
    "IICvAEI9PMGa",
    "E58ChcNTPSC2",
    "c5rECBsoPUtn",
    "BA0iijShPXza",
    "MgFrB2SZPefH",
    "aoWg7FJIPh1v",
    "lsiAHD0vPrRW",
    "-AfpM2luPxs8"
   ],
   "name": "Module-1-Lab-weather-pred-hand-coded.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
