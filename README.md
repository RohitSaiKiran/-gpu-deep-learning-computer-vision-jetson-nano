# -gpu-deep-learning-computer-vision-jetson-nano

This project demonstrates GPU-accelerated deep learning, time series forecasting, and computer vision on the Jetson Nano, optimized for edge computing.  
It highlights parallel programming techniques and efficient ML pipelines on embedded hardware.

### Why This Project
Most Jetson Nano demos show only basic inference or simple examples. This project demonstrates production-style edge AI capabilities, with properly structured code, real datasets, GPU-optimized pipelines, and meaningful use cases:

- Learn GPU parallel programming concepts.
- Deploy deep learning on constrained hardware.
- Apply computer vision and time series prediction at the edge.
- Showcase Jetson Nano as a viable edge AI platform.

### Highlights :
- Real-time, GPU-accelerated ML & CV on edge hardware.
- Parallel programming and embedded AI workflows.
- Optimized for performance on resource-constrained devices.

### Labs :

- **Lab 1**: Mandelbrot fractal rendering with PyCUDA, demonstrating GPU parallelism.
- **Lab 2**: GPU-accelerated matrix operations and benchmarks using PyCUDA, CuPy, and Numba.
- **Lab 3**: Time series forecasting and classification with PyTorch (GRU and Linear models).
- **Lab 4**: Real-time image and video processing, feature tracking, and optical flow with OpenCV.

### Technologies Used :
- **Hardware**: NVIDIA Jetson Nano
- **Frameworks & Libraries**: CUDA, PyCUDA, CuPy, Numba, PyTorch, OpenCV, Python, Jupyter Notebooks
- **Domains**: Parallel Programming, Deep Learning, Computer Vision, Time Series Forecasting

### Prerequisites
- NVIDIA Jetson Nano (with CUDA drivers & JetPack)
- Python 3.6+
- PyTorch, cuPy, Numba, PyCUDA
- OpenCV
- Matplotlib, pandas
